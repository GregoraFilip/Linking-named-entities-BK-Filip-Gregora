{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec09843",
   "metadata": {},
   "source": [
    "# Linking named entities\n",
    "by Filip Gregora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "06c163ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from itertools import combinations\n",
    "from string import punctuation\n",
    "import math\n",
    "import os\n",
    "import xml.etree.ElementTree as elt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62645ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>Novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>Označena SLU v levé axile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      Novalgin\n",
       "3     symptom    Označena SLU v levé axile.\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             Založení TE l.sin\n",
       "7   procedura                   Cytostatika\n",
       "8  NE symptom         přiměřené echogenity,\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/NER_entities.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6678d27",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "At the beginning we want to explore data.\n",
    "\n",
    "- We can see that somewhere there is big letter at the beginning (but be carefull when whole first word is written in upper case)\n",
    "- Somewhere at the end is interpuncion\n",
    "- There are lots of duplicates\n",
    "- the length of text is variable and the longest has 20 words (this can be problem in the future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f247a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2588"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "b494df98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      novalgin\n",
       "3     symptom     označena SLU v levé axile\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             založení TE l.sin\n",
       "7   procedura                   cytostatika\n",
       "8  NE symptom          přiměřené echogenity\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(string):\n",
    "    string = string.strip(\" \" + \"\".join(punctuation))\n",
    "    # Remove first upper letter if not all letters are upper\n",
    "    if len(string) >= 2:\n",
    "        string = string[0].lower() + string[1:] if string[1].islower() else string\n",
    "    # Replace multiple whitespaces with one\n",
    "    return \" \".join(string.split())\n",
    "\n",
    "def clean_db(db):\n",
    "    db_copy = db.copy()\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(clean)\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].drop_duplicates()\n",
    "    return db_copy.dropna()\n",
    "\n",
    "data = clean_db(data)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bc06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1 | 2: 3 | 3: 7 | 4: 15 | 5: 31 | 6: 63 | 7: 127 | 8: 255 | 9: 511 | 10: 1023 | 11: 2047 | 12: 4095 | 13: 8191 | 14: 16383 | 15: 32767 | 16: 65535 | 17: 131071 | 18: 262143 | 19: 524287 | 20: 1048575 | "
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comb_sum(j):\n",
    "    sum = 0\n",
    "    for i in range(j, 0, -1):\n",
    "        sum += math.comb(j,i)\n",
    "\n",
    "    return sum\n",
    "\n",
    "for i in range(1, 21):\n",
    "    print(i, comb_sum(i), sep = \": \", end = \" | \")\n",
    "    \n",
    "lenght_data = data[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "len(lenght_data[lenght_data >= 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc45a11",
   "metadata": {},
   "source": [
    "## Linking\n",
    "Our approach to linking entities is:\n",
    "- Link words to some medicinal database.\n",
    "- Let some pretrained language model to choose the best from them.\n",
    "\n",
    "So I can compare I decided to use two approaches for linking. The first one is to use international mesh and access it via web API of NIH (National Institute of Health).\n",
    "\n",
    "The second is to use czech mesh. I accessed it from predownloaded file.\n",
    "\n",
    "### Linking to international MESH through NIH\n",
    "Mash is international medical databaze: https://uts.nlm.nih.gov/uts/.\n",
    "\n",
    "I tried search all combinations of words from text in databaze. The longer combinations have higher priority. \n",
    "\n",
    "There is one big problem, the complexity grows exponentially with the lenght of the words (in the worst case for lenght of 20 we have to try around 10^6 combinations). My solution for this problem is go from bottom up, start with lenght 1 and continue only with combinations which success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "97cd1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C0240430', \"Mee's line\"), ('C0259779', 'Fibrous Dysplasia')]\n"
     ]
    }
   ],
   "source": [
    "# Do not search in databaze if it number or it is too short (shorter than 2)\n",
    "def filter_short(string):\n",
    "    return len(string) < 2 or string.isdigit()\n",
    "    \n",
    "    \n",
    "def print_stats(data_list):\n",
    "    empty = len(data_list[data_list.apply(lambda x: len(x) == 0)])\n",
    "    print(f\"Number of empty: {empty} ({empty / len(data_list) * 100} %)\")\n",
    "\n",
    "    number_of_matches = data_list.apply(lambda x: len(x))\n",
    "    print(f\"Mean from number of matches: {number_of_matches.mean()}\")\n",
    "    print(f\"Median from number of matches: {number_of_matches.median()}\")\n",
    "    print(f\"Maximal of matches: {number_of_matches.max()}\")\n",
    "    \n",
    "    \n",
    "def from_string_to_list(string):\n",
    "    result = []\n",
    "    for j in string.strip(\"[]()\").split(\"), (\"):\n",
    "        if len(j) == 0:\n",
    "            continue\n",
    "        result.append(tuple([s.strip(\"'\\\" \\\\\") for s in j.split(\"', \")]))\n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "def from_string_to_tuple(string):\n",
    "    if string == \"N/A\":\n",
    "        return\n",
    "    result = [i.strip(\"\\\\\\\"'()\") for i in string.strip(\"\\\\\\\" )('\").split(\", \")]\n",
    "    return (result[0], result[1], \", \".join(result[2:]))\n",
    "\n",
    "\n",
    "def from_string_to_dict(string):\n",
    "    result = {}\n",
    "    for j in string.strip(\"{} \").split(\"], \"):\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        i = list(j.split(\": [\"))\n",
    "        assert len(i) == 2\n",
    "        result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_list(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def from_string_to_dict_to_tuple(string):\n",
    "    result = {}\n",
    "    # string = string.replace(\"\\\\\", \"\")\n",
    "    # string = string.replace(\"\\\\\\'\", \"\")\n",
    "    for j in re.split(\"(\\)| None), ('|\\\")\", string.strip(\"{} \")):\n",
    "        if j in [\"\", ')', ' None', \"'\", '\"']:\n",
    "            continue\n",
    "        i = list(j.split(\": (\"))\n",
    "        if len(i) == 1:\n",
    "            i[0] = i[0].split(\": None\")[0].strip(\": \")\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = None\n",
    "        else:\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_tuple(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "print(from_string_to_list(\"[('C0240430', \"\"Mee's line\"\"), ('C0259779', 'Fibrous Dysplasia')]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "b12d3124-6156-463f-872f-67e823148df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kalubru'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\\\\\'kalubru\\\\\\'\".strip(\" \\'\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b15b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"APIkeys/NIH\", \"r\") as f:\n",
    "    NIH_api = f.read()\n",
    "\n",
    "def mash_search_basic(string):\n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    for j in range(len(splitted_input), 0, -1):\n",
    "        for string in combinations(splitted_input, j): \n",
    "            if filter_short(\" \".join(string)):\n",
    "                continue\n",
    "                \n",
    "            path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "            query = {\n",
    "                     'string': \" \".join(string),\n",
    "                     'apiKey':NIH_api,\n",
    "            }\n",
    "            res = requests.get(path, params=query)\n",
    "\n",
    "            if res.status_code <= 200:\n",
    "                data = json.loads(res.text)\n",
    "                for j in data[\"result\"][\"results\"]:\n",
    "                    result.append((j[\"ui\"], j[\"name\"]))\n",
    "            else:\n",
    "                print(res.status_code, res.text)\n",
    "        \n",
    "        if len(result) != 0:\n",
    "            break\n",
    "                        \n",
    "    return result\n",
    "        \n",
    "    \n",
    "def search_with_inclusion(string, func, output_state = False):\n",
    "    if (output_state):\n",
    "        global count\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    last_result = []\n",
    "    lenght = len(splitted_input)\n",
    "    \n",
    "    for j in range(1, lenght + 1):\n",
    "        splitted_dict={}\n",
    "        for elem in splitted_input:\n",
    "            splitted_dict[j] = False\n",
    "                    \n",
    "        for words in combinations(splitted_input, j):\n",
    "            data = func(\" \".join(words))\n",
    "            if len(data) != 0:\n",
    "                for j in words:\n",
    "                    splitted_dict[j] = True\n",
    "                if filter_short(\" \".join(words)):\n",
    "                    continue\n",
    "                result.append(data)\n",
    "\n",
    "        splitted_input = [j for j, i in splitted_dict.items() if i]\n",
    "        if len(splitted_input) == 0:\n",
    "            break\n",
    "        else:\n",
    "            last_result, result = result, []\n",
    "        \n",
    "    temp = []\n",
    "    for j in last_result:\n",
    "        temp += list(enumerate(j))\n",
    "    return [j for (i, j) in sorted(temp)]\n",
    "    \n",
    "    \n",
    "def mash_search(string):\n",
    "    path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "    query = {\n",
    "             'string': string,\n",
    "             'apiKey':NIH_api,\n",
    "    }\n",
    "    res = requests.get(path, params=query)\n",
    "\n",
    "    if res.status_code <= 200:\n",
    "        data = json.loads(res.text)          \n",
    "        return [(j[\"ui\"], j[\"name\"]) for j in data[\"result\"][\"results\"]]\n",
    "    else:\n",
    "        print(res.status_code, res.text)\n",
    "        return []\n",
    "    \n",
    "\n",
    "def search_db(db, func):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(func)\n",
    "    return db \n",
    "    \n",
    "    \n",
    "def search_db_mash(db):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(mash_search_basic)\n",
    "    return db    \n",
    "\n",
    "\n",
    "def search_db_mash_optimized(db):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(lambda x: search_with_inclusion(x, mash_search))\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5939f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_mash.csv\"):\n",
    "    data_mash = pd.read_csv(\"saved_search/data_mash.csv\")\n",
    "    data_mash.index = data_mash[\"Unnamed: 0\"]\n",
    "    data_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    data_mash[\"search\"] = data_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    data_mash = search_db_mash_optimized(data_mash)\n",
    "    data_mash.to_csv(\"saved_search/data_mash.csv\")\n",
    "    \n",
    "print_stats(data_mash[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef10f4",
   "metadata": {},
   "source": [
    "#### Not assigned\n",
    "If we look at the random sample of 10 texts, which are not assigned, then we can see that in five of them there is typographical mistake (*\"nejsou zn.plicní hpertenze\"* = *\"nejsou zn. plicní hypertenze\"*, *\"kumulce a nehomogenity\"* = *\"kumulace a nehomogenita\"*, *\"ceriucal\"* = *\"cerucal\"*, *\"paitace\"* = *\"palpitace\"*, *\"mamily klidné\"* = ?). Others five are correct medical term, but in some non-typical grammatical form.\n",
    "\n",
    "If we try to improve them we get 50 % improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a153e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>nejsou zn. plicní hypertenze</td>\n",
       "      <td>[(C0020542, Pulmonary Hypertension), (C0152171...</td>\n",
       "      <td>NE symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>hormostenické</td>\n",
       "      <td>[]</td>\n",
       "      <td>NE symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>kumulace a nehomogenita</td>\n",
       "      <td>[]</td>\n",
       "      <td>symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>biopsie</td>\n",
       "      <td>[(C0005558, Biopsy), (C0220797, biopsy charact...</td>\n",
       "      <td>procedura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>chemobioterapie</td>\n",
       "      <td>[]</td>\n",
       "      <td>procedura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>dysmorfické</td>\n",
       "      <td>[(C0005887, Body Dysmorphic Disorders)]</td>\n",
       "      <td>symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>anikterické</td>\n",
       "      <td>[]</td>\n",
       "      <td>NE symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>cerucal</td>\n",
       "      <td>[(C0701450, Cerucal)]</td>\n",
       "      <td>medikace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>palpitace</td>\n",
       "      <td>[(C0030252, Palpitations), (C0549267, Palpitat...</td>\n",
       "      <td>NE symptom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>mamily klidné</td>\n",
       "      <td>[]</td>\n",
       "      <td>NE symptom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  \\\n",
       "Unnamed: 0                                 \n",
       "878         nejsou zn. plicní hypertenze   \n",
       "91                         hormostenické   \n",
       "5240             kumulace a nehomogenita   \n",
       "3728                             biopsie   \n",
       "1125                     chemobioterapie   \n",
       "2479                         dysmorfické   \n",
       "4981                         anikterické   \n",
       "1134                             cerucal   \n",
       "5089                           palpitace   \n",
       "1129                       mamily klidné   \n",
       "\n",
       "                                                       search       label  \n",
       "Unnamed: 0                                                                 \n",
       "878         [(C0020542, Pulmonary Hypertension), (C0152171...  NE symptom  \n",
       "91                                                         []  NE symptom  \n",
       "5240                                                       []     symptom  \n",
       "3728        [(C0005558, Biopsy), (C0220797, biopsy charact...   procedura  \n",
       "1125                                                       []   procedura  \n",
       "2479                  [(C0005887, Body Dysmorphic Disorders)]     symptom  \n",
       "4981                                                       []  NE symptom  \n",
       "1134                                    [(C0701450, Cerucal)]    medikace  \n",
       "5089        [(C0030252, Palpitations), (C0549267, Palpitat...  NE symptom  \n",
       "1129                                                       []  NE symptom  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_sample = data_mash[data_mash[\"search\"].apply(lambda x: len(x) == 0)].sample(10, random_state=42)\n",
    "\n",
    "# Because of my mistake (I had worser clean_db), the code above generate different sample than I have worked with.\n",
    "# So I have to create the sample by hand:\n",
    "empty_sample = data_mash.loc[[878, 91, 5240, 3728, 1125, 2479, 4981, 1134, 5089, 1129]]\n",
    "\n",
    "empty_sample[\"text\"][878] = \"nejsou zn. plicní hypertenze\"\n",
    "empty_sample[\"text\"][91] = \"hormostenické\"\n",
    "empty_sample[\"text\"][5240] = \"kumulace a nehomogenita\"\n",
    "empty_sample[\"text\"][3728] = \"biopsie\"\n",
    "empty_sample[\"text\"][1125] = \"chemobioterapie\"\n",
    "empty_sample[\"text\"][2479] = \"dysmorfické\"\n",
    "empty_sample[\"text\"][4981] = \"anikterické\"\n",
    "empty_sample[\"text\"][1134] = \"cerucal\"\n",
    "empty_sample[\"text\"][5089] = \"palpitace\"\n",
    "empty_sample[\"text\"][1129] = \"mamily klidné\"\n",
    "\n",
    "empty_sample = search_db_mash_optimized(empty_sample)\n",
    "empty_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a45dc4",
   "metadata": {},
   "source": [
    "There is one mistake which we can correct automaticly and it is not having space after punctuation mark. We can see that if we have space after punctuation then it find something, else it didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9881b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(search_with_inclusion(\"zn. plicní\", mash_search)))\n",
    "print(len(search_with_inclusion(\"zn.plicní\", mash_search)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a1248",
   "metadata": {},
   "source": [
    "We can see that there is around 150 examples of this mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede5ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            return False\n",
    " \n",
    "    return True\n",
    "\n",
    "def insert_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            string = string[:i+1] + \" \" + string[i+1:]\n",
    " \n",
    "    return string\n",
    "\n",
    "inserted_space_data = data.copy()\n",
    "inserted_space_data[\"text\"] = inserted_space_data[\"text\"].apply(insert_space_after_punc)\n",
    "no_space = data[~data[\"text\"].apply(is_space_after_punc)]\n",
    "len(no_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2ba076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_mash_inserted_space.csv\"):\n",
    "    inserted_space_data_mash = pd.read_csv(\"saved_search/data_mash_inserted_space.csv\")\n",
    "    inserted_space_data_mash.index = inserted_space_data_mash[\"Unnamed: 0\"]\n",
    "    inserted_space_data_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    inserted_space_data_mash[\"search\"] = inserted_space_data_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    inserted_space_data_mash = data_mash.copy()\n",
    "    no_space[\"text\"] = no_space[\"text\"].apply(insert_space_after_punc)\n",
    "    for i in no_space.index:\n",
    "        inserted_space_data_mash[\"search\"][i] = search_with_inclusion(no_space[\"text\"][i], mash_search)\n",
    "        inserted_space_data_mash[\"text\"][i] = no_space[\"text\"][i]\n",
    "    inserted_space_data_mash.to_csv(\"saved_search/data_mash_inserted_space.csv\")    \n",
    "        \n",
    "print_stats(data_mash[\"search\"])\n",
    "print()\n",
    "print_stats(inserted_space_data_mash[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25133cb",
   "metadata": {},
   "source": [
    "Thanks to this upgrade we improved search by finding 40 new matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03172cc",
   "metadata": {},
   "source": [
    "### Linking to CZ Mash through Medvik \n",
    "\n",
    "Now we try to link through czech mash, I have downloaded it from NLK (národní lékařská knihovna): https://nlk.cz/pro-knihovny/data/#mesh-cz\n",
    "\n",
    "I called this linking as Medvik, because there is web service called Medvik: https://www.medvik.cz/bmc/subject.do, where you can search in czech mash.\n",
    "\n",
    "I used already improved methods from Mash_search. First I experimenced with search, which tests if contains gived text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d500763",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = elt.parse('databaze/MeSH2023_Marc21_Alma.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbaf7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternize(string):\n",
    "    result = []\n",
    "    for i in string:\n",
    "        if i in '<([{\\\\^-=$!|]})?*+.>]':\n",
    "            result.append(\"\\\\\" + i)\n",
    "        else:\n",
    "            result.append(i)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def medvik_search(string, init_pattern, last_pattern):\n",
    "    result = []\n",
    "    pattern = re.compile(f\"{init_pattern}{patternize(string)}{last_pattern}\",re.IGNORECASE)\n",
    "    \n",
    "    for child in content:\n",
    "        for subchild in child.iter(\"{http://www.loc.gov/MARC21/slim}subfield\"):\n",
    "            if subchild.text and pattern.match(subchild.text) is not None:\n",
    "                try:\n",
    "                    code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "                    name = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"150\" ][0][0].text\n",
    "                    result.append((code, name))\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    break                \n",
    "    return result\n",
    "\n",
    "\n",
    "def medvik_search_match(string):\n",
    "    return medvik_search(string, \".*\", \".*\")\n",
    "\n",
    "\n",
    "def medvik_search_words(string):      \n",
    "    return medvik_search(string, \".* \", \" .*\")\n",
    "\n",
    "\n",
    "def medvik_search_exact(string):              \n",
    "    return medvik_search(string, \"^\", \"$\")\n",
    "\n",
    "\n",
    "def medvik_search_combined(string):\n",
    "    result = medvik_search(string, \"^\", \"$\")\n",
    "    if len(result) == 0:\n",
    "        result = medvik_search(string, \".* \", \" .*\")\n",
    "    if len(result) == 0:\n",
    "        result = medvik_search(string, \".*\", \".*\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def search_db_medvik_match(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_match, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_exact(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_exact, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_words(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_words, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_combined(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_combined, output_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ec8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_medvik_contains.csv\"):\n",
    "    data_medvik_contains = pd.read_csv(\"saved_search/data_medvik_contains.csv\")\n",
    "    data_medvik_contains.index = data_medvik_contains[\"Unnamed: 0\"]\n",
    "    data_medvik_contains.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    data_medvik_contains[\"search\"] = data_medvik_contains[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    data_medvik_contains = search_db_medvik_match(inserted_space_data)\n",
    "    data_medvik_contains.to_csv(\"saved_search/data_medvik_contains.csv\")\n",
    "    \n",
    "print_stats(inserted_space_data_mash[\"search\"])\n",
    "print()\n",
    "print_stats(data_medvik_contains[\"search\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6567ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1904, 1720, 0, 27715, 1722, 94, 9, 10724, 0, 112]\n",
      "number of searches longer than 100 matches in data_medvik_contains: 1017\n"
     ]
    }
   ],
   "source": [
    "print([i for i in data_medvik_contains[\"search\"].apply(lambda x: len(x)).sample(10, random_state=42)])\n",
    "\n",
    "temp = data_medvik_contains[\"search\"].apply(lambda x: len(x))\n",
    "print(f\"number of searches longer than 100 matches in data_medvik_contains: {len(temp[temp > 100])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2418733",
   "metadata": {},
   "source": [
    "We can see, that for some examples this is working well. But for some we have really lots of samples whose lenght grows exponentially.\n",
    "\n",
    "For this reasons it might be better to use some different match method instead:\n",
    "- First method is contain search (I used it before) - test if contains given text\n",
    "- Next method is word search - test if contains given text as word (there are spaces around)\n",
    "- Next method is exact search - test if contains exactly given text\n",
    "- The last method is combined search - first text exact, then word, then contains (if some success then end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53dd6c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 2265.2\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 27715\n",
      "\n",
      "Words match\n",
      "Number of empty: 6 (30.0 %)\n",
      "Mean from number of matches: 194.0\n",
      "Median from number of matches: 5.5\n",
      "Maximal of matches: 1918\n",
      "\n",
      "Exact match\n",
      "Number of empty: 11 (55.00000000000001 %)\n",
      "Mean from number of matches: 3.05\n",
      "Median from number of matches: 0.0\n",
      "Maximal of matches: 22\n",
      "\n",
      "Combined match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 261.95\n",
      "Median from number of matches: 6.5\n",
      "Maximal of matches: 1904\n"
     ]
    }
   ],
   "source": [
    "test_data = inserted_space_data.sample(20, random_state=42)\n",
    "\n",
    "if os.path.isfile(\"saved_search/test_medvik.csv\"):\n",
    "    test_data = pd.read_csv(\"saved_search/test_medvik.csv\")\n",
    "    test_data[\"search_match\"] = test_data[\"search_match\"].apply(from_string_to_list)\n",
    "    test_data[\"search_exact\"] = test_data[\"search_exact\"].apply(from_string_to_list)\n",
    "    test_data[\"search_words\"] = test_data[\"search_words\"].apply(from_string_to_list)\n",
    "    test_data[\"search_combined\"] = test_data[\"search_combined\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    test_data[\"search_match\"] = search_db_medvik_match(test_data)[\"search\"]\n",
    "    test_data[\"search_exact\"] = search_db_medvik_exact(test_data)[\"search\"]\n",
    "    test_data[\"search_words\"] = search_db_medvik_words(test_data)[\"search\"]\n",
    "    test_data[\"search_combined\"] = search_db_medvik_combined(test_data)[\"search\"]\n",
    "    test_data.to_csv(\"saved_search/test_medvik.csv\")\n",
    "    \n",
    "print(\"Contains match\")\n",
    "print_stats(test_data[\"search_match\"])\n",
    "print(\"\\nWords match\")\n",
    "print_stats(test_data[\"search_words\"])\n",
    "print(\"\\nExact match\")\n",
    "print_stats(test_data[\"search_exact\"])\n",
    "print(\"\\nCombined match\")\n",
    "print_stats(test_data[\"search_combined\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9b5a0",
   "metadata": {},
   "source": [
    "We can see that using exact match we get rid of the long matches but it have quite low success rate. Using words match is something in the middle (not good in both ways).\n",
    "\n",
    "As last option we used combined match (first try exact, if don't success then words, then only match). This seems as the best methods (this doesn't create too large lists and has the same number of empty matches as contains match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05709eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_medvik_combined.csv\"):\n",
    "    data_medvik_combined = pd.read_csv(\"saved_search/data_medvik_combined.csv\")\n",
    "    data_medvik_combined.index = data_medvik_combined[\"Unnamed: 0\"]\n",
    "    data_medvik_combined.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    data_medvik_combined[\"search\"] = data_medvik_combined[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    data_medvik_combined = search_db_medvik_combined(inserted_space_data)\n",
    "    data_medvik_combined.to_csv(\"saved_search/data_medvik_combined.csv\")\n",
    "       \n",
    "print_stats(data_medvik_combined[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4d23d",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "It is possible to get duplicates in list of matches, when getting the same match from two different words from text (or combinations of the same lenght) \n",
    "\n",
    "In mash search there are few duplicates, but in medvik search it can be serious problem - we can see, that maximum of matches in contains search is reduced nearly by 15 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25363344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inserted_space_data_mash[~inserted_space_data_mash[\"search\"].apply(lambda x: len(set(x)) == len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2e0d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n",
      "\n",
      "\n",
      "After removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.33927934356047\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1625.7213699607564\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 29327\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 481.9782376025687\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "def remove_dup_preserve_order(l):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in l if not (x in seen or seen_add(x))]\n",
    "\n",
    "print(\"Before removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_stats(inserted_space_data_mash[\"search\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_stats(data_medvik_contains[\"search\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_stats(data_medvik_combined[\"search\"])\n",
    "\n",
    "inserted_space_data_mash[\"search\"] = inserted_space_data_mash[\"search\"].apply(remove_dup_preserve_order)\n",
    "data_medvik_contains[\"search\"] = data_medvik_contains[\"search\"].apply(remove_dup_preserve_order)\n",
    "data_medvik_combined[\"search\"] = data_medvik_combined[\"search\"].apply(remove_dup_preserve_order)\n",
    "\n",
    "print(\"\\n\\nAfter removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_stats(inserted_space_data_mash[\"search\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_stats(data_medvik_contains[\"search\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_stats(data_medvik_combined[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2177a4b",
   "metadata": {},
   "source": [
    "## Choosing best match with Chat GPT\n",
    "The idea behind our model is first link term to database and then choose the best one by some pretrained language model.\n",
    "\n",
    "I use GPT-3.5, because it is free to access with limitations (There are some limits of access per day. And there is limited number of access per account. Then we have to pay.), it is fast and it is well known.\n",
    "\n",
    "The message to GPT is in this format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5917d",
   "metadata": {},
   "source": [
    "Který z nadcházejících popisů medicínských pojmů nejlépe popisuje text: \"[MEDICAL TERM]\":\n",
    "\n",
    "    1. [DESCRIPTION_N.1] (pojem: [TERM_N.1])\n",
    "    2. [DESCRIPTION_N.2] (pojem: [TERM_N.2])\n",
    "    ...\n",
    "    \n",
    "Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a818507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "with open(\"APIkeys/NIH\", \"r\") as f:\n",
    "    NIH_api = f.read()\n",
    "\n",
    "def find_by_code_medvik(string):\n",
    "    if len(string) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    for child in content:\n",
    "        try:\n",
    "            code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "            if code == string:\n",
    "                d = [i.iter(\"{http://www.loc.gov/MARC21/slim}subfield\") for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"680\"][0]\n",
    "                return next(d).text\n",
    "        except IndexError:\n",
    "            continue      \n",
    "            \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def find_by_code_mash(string):\n",
    "    path = f'https://uts-ws.nlm.nih.gov/rest/content/current/CUI/{string}'\n",
    "    query = {\n",
    "             'apiKey':NIH_api,\n",
    "    }\n",
    "    res = requests.get(path, params=query)\n",
    "    \n",
    "    if res.status_code <= 200:\n",
    "        try:\n",
    "            data = json.loads(res.text)\n",
    "            definition = data[\"result\"][\"definitions\"]\n",
    "\n",
    "            if re.match(\"https://uts-ws.nlm.nih.gov/\", definition) is not None:\n",
    "                path = definition\n",
    "                res = requests.get(path,params=query)\n",
    "                try:\n",
    "                    return [i[\"value\"] for i in json.loads(res.text)[\"result\"] if i[\"rootSource\"] == \"MSHCZE\"][0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                try:\n",
    "                    return [i[\"value\"] for i in json.loads(res.text)[\"result\"] if i[\"rootSource\"] == \"MSH\"][0]\n",
    "                except IndexError:\n",
    "                    definition = \"NONE\"\n",
    "        except Exception:\n",
    "            definition = \"NONE\"\n",
    "            print(string, res.text)\n",
    "        \n",
    "        if definition == \"NONE\":\n",
    "            return data[\"result\"][\"name\"]\n",
    "        \n",
    "        return definition\n",
    "    else:\n",
    "        print(string)\n",
    "        print(res.status_code, res.text)\n",
    "        \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17707115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_chat(message):\n",
    "    with open(\"APIkeys/chatGTP\", \"r\") as f:\n",
    "        chatgpt_api = f.read()\n",
    "\n",
    "    client = OpenAI(api_key=chatgpt_api)\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_message_chatGTP(string, li):\n",
    "    result = [f\"Který z nadcházejících popisů medicínských pojmů nejlépe popisuje text: \\\"{string}\\\":\\n\"]\n",
    "    j = 1\n",
    "    for i in li:\n",
    "        result.append(f\"{j}. {i}\\n\")\n",
    "        j += 1\n",
    "    result.append(\"Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE.\")\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def message_chatGPT(string, li, find):\n",
    "    searched_li = [find(i[0]) + f\" (pojem: {i[1]})\" for i in li]\n",
    "    return create_message_chatGTP(string, searched_li)\n",
    "\n",
    "\n",
    "def from_chatGPT(result, li, find):\n",
    "    try:\n",
    "        i = int(result.choices[0].message.content.split(\".\")[0].strip(\" \")) - 1\n",
    "        return (li[i][0], li[i][1], find(li[i][0]))\n",
    "    except ValueError:\n",
    "        return None\n",
    "    except IndexError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650e610",
   "metadata": {},
   "source": [
    "Because ChatGPT has problem with long messages (and sometimes we get really long results with medvik_combined), we have to restrict these messages and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6876643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"saved_search/explanation_sample.csv\"):\n",
    "    explanation = pd.read_csv(\"saved_search/explanation_sample.csv\")\n",
    "    explanation.index = explanation[\"Unnamed: 0\"]\n",
    "    explanation.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    explanation[\"mash_explanation\"] = explanation[\"mash_explanation\"].fillna(value=\"N/A\").apply(from_string_to_tuple)\n",
    "    explanation[\"medvik_explanation\"] = explanation[\"medvik_explanation\"].fillna(value=\"N/A\").apply(from_string_to_tuple)\n",
    "    explanation[\"mash_search\"] = explanation[\"mash_search\"].apply(from_string_to_list)\n",
    "    explanation[\"medvik_search_combined\"] = explanation[\"medvik_search_combined\"].apply(from_string_to_list)\n",
    "else:\n",
    "    explanation = results.sample(100, random_state=38)\n",
    "    explanation[\"mash_explanation\"] = \"N/A\"\n",
    "    for j in explanation.index:\n",
    "        message = message_chatGTP(explanation[\"text\"][j], explanation[\"mash_search\"][j], find_by_code_mash)\n",
    "        response = send_to_chat(message)\n",
    "        explanation[\"mash_explanation\"][j] = from_chatGPT(response, explanation[\"mash_search\"][j], find_by_code_mash)     \n",
    "        \n",
    "#         If the message is too long we cannot send it to chatGPT, so we drop shorter messages.\n",
    "        if len(explanation[\"medvik_search_combined\"][j]) > 50:\n",
    "            continue\n",
    "        message = message_chatGPT(explanation[\"text\"][j], explanation[\"medvik_search_combined\"][j], find_by_code_medvik)\n",
    "        response = send_to_chat(message)\n",
    "        explanation[\"medvik_explanation\"][j] = from_chatGPT(response, explanation[\"medvik_search_combined\"][j], find_by_code_medvik)\n",
    "    explanation.to_csv(\"saved_search/explanation_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8fdcd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>mash_search</th>\n",
       "      <th>medvik_search_combined</th>\n",
       "      <th>mash_explanation</th>\n",
       "      <th>medvik_explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>KI100</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st. p. tru-cut biopsii</td>\n",
       "      <td>[(C1170898, Companion P/ST 1000ML), (C4015802,...</td>\n",
       "      <td>[(D000039, peritonzilární absces), (D000081182...</td>\n",
       "      <td>(C5700874, Percutaneous pulmonary artery revas...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>osobní anamnéza</td>\n",
       "      <td>konizace čípku</td>\n",
       "      <td>[(C0195324, Conization)]</td>\n",
       "      <td>[(D002583, nádory děložního čípku), (D019092, ...</td>\n",
       "      <td>(C0195324, Conization, Kruhovité kuželovité vy...</td>\n",
       "      <td>(D019092, konizace děložního čípku, Kruhovité ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>procedura</td>\n",
       "      <td>operace: ITP</td>\n",
       "      <td>[(C0398650, Immune thrombocytopenic purpura), ...</td>\n",
       "      <td>[(D007293, inosintrifosfát)]</td>\n",
       "      <td>(C3842543, Idiopathic thrombocytopenia (ITP), ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>symptom</td>\n",
       "      <td>neostře konturované ložisko 7x5mm</td>\n",
       "      <td>[(C0241148, Cutaneous plaque), (C1533591, Calc...</td>\n",
       "      <td>[(D001253, astrocyty), (D002833, choroiditida)...</td>\n",
       "      <td>(C0235456, Thyroid nodular, Thyroid nodular)</td>\n",
       "      <td>(D002833, choroiditida, Zánět cévnatky, zadní ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label                               text  \\\n",
       "Unnamed: 0                                                       \n",
       "1633             NE symptom                              KI100   \n",
       "5536              procedura             st. p. tru-cut biopsii   \n",
       "412         osobní anamnéza                     konizace čípku   \n",
       "4517              procedura                       operace: ITP   \n",
       "5757                symptom  neostře konturované ložisko 7x5mm   \n",
       "\n",
       "                                                  mash_search  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                       []   \n",
       "5536        [(C1170898, Companion P/ST 1000ML), (C4015802,...   \n",
       "412                                  [(C0195324, Conization)]   \n",
       "4517        [(C0398650, Immune thrombocytopenic purpura), ...   \n",
       "5757        [(C0241148, Cutaneous plaque), (C1533591, Calc...   \n",
       "\n",
       "                                       medvik_search_combined  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                       []   \n",
       "5536        [(D000039, peritonzilární absces), (D000081182...   \n",
       "412         [(D002583, nádory děložního čípku), (D019092, ...   \n",
       "4517                             [(D007293, inosintrifosfát)]   \n",
       "5757        [(D001253, astrocyty), (D002833, choroiditida)...   \n",
       "\n",
       "                                             mash_explanation  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                     None   \n",
       "5536        (C5700874, Percutaneous pulmonary artery revas...   \n",
       "412         (C0195324, Conization, Kruhovité kuželovité vy...   \n",
       "4517        (C3842543, Idiopathic thrombocytopenia (ITP), ...   \n",
       "5757             (C0235456, Thyroid nodular, Thyroid nodular)   \n",
       "\n",
       "                                           medvik_explanation  \n",
       "Unnamed: 0                                                     \n",
       "1633                                                     None  \n",
       "5536                                                     None  \n",
       "412         (D019092, konizace děložního čípku, Kruhovité ...  \n",
       "4517                                                     None  \n",
       "5757        (D002833, choroiditida, Zánět cévnatky, zadní ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d125c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explanation[explanation[\"medvik_search_combined\"].apply(lambda x: len(x) > 50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018cda",
   "metadata": {},
   "source": [
    "## Conclusion Basic Access\n",
    "There I am going to evaluate the basic access for linking entities.\n",
    "\n",
    "### Results for Linking\n",
    "Now we look how we have been successful with linking to database with respect to different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f3dd34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>mash_search</th>\n",
       "      <th>medvik_search_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>[(C0030848, Peyronie Disease), (C0227365, Taen...</td>\n",
       "      <td>[(D000077275, fibrózní dysplazie kraniofaciáln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>[(C0600558, Neoadjuvant Therapy), (C1422359, S...</td>\n",
       "      <td>[(D000014, abnormality vyvolané léky), (D00313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>[(C0917937, Novalgin)]</td>\n",
       "      <td>[(D004177, metamizol)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text  \\\n",
       "0    symptom  jemný fibrózní proužek   \n",
       "1  procedura       neoadjuvantní CHT   \n",
       "2   medikace                novalgin   \n",
       "\n",
       "                                         mash_search  \\\n",
       "0  [(C0030848, Peyronie Disease), (C0227365, Taen...   \n",
       "1  [(C0600558, Neoadjuvant Therapy), (C1422359, S...   \n",
       "2                             [(C0917937, Novalgin)]   \n",
       "\n",
       "                              medvik_search_combined  \n",
       "0  [(D000077275, fibrózní dysplazie kraniofaciáln...  \n",
       "1  [(D000014, abnormality vyvolané léky), (D00313...  \n",
       "2                             [(D004177, metamizol)]  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = inserted_space_data.copy()\n",
    "results[\"mash_search\"] = inserted_space_data_mash[\"search\"]\n",
    "results[\"medvik_search_combined\"] = data_medvik_combined[\"search\"]\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "5e6946b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osobní anamnéza:\n",
      "Number of empty: 11 (5.14018691588785 %)\n",
      "Mean from number of matches: 22.939252336448597\n",
      "Median from number of matches: 24.0\n",
      "Maximal of matches: 86\n",
      "Number of empty: 18 (8.411214953271028 %)\n",
      "Mean from number of matches: 459.1588785046729\n",
      "Median from number of matches: 11.5\n",
      "Maximal of matches: 13185\n",
      "\n",
      "NE osobní anamnéza:\n",
      "Number of empty: 4 (6.557377049180328 %)\n",
      "Mean from number of matches: 20.83606557377049\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 75\n",
      "Number of empty: 14 (22.950819672131146 %)\n",
      "Mean from number of matches: 190.34426229508196\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 5777\n",
      "\n",
      "medikace:\n",
      "Number of empty: 73 (23.934426229508198 %)\n",
      "Mean from number of matches: 14.462295081967213\n",
      "Median from number of matches: 8.0\n",
      "Maximal of matches: 82\n",
      "Number of empty: 101 (33.114754098360656 %)\n",
      "Mean from number of matches: 96.88196721311475\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 5134\n",
      "\n",
      "NE medikace:\n",
      "Number of empty: 1 (6.25 %)\n",
      "Mean from number of matches: 19.3125\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 50\n",
      "Number of empty: 4 (25.0 %)\n",
      "Mean from number of matches: 38.1875\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 233\n",
      "\n",
      "symptom:\n",
      "Number of empty: 36 (6.132879045996593 %)\n",
      "Mean from number of matches: 22.938671209540033\n",
      "Median from number of matches: 21.0\n",
      "Maximal of matches: 125\n",
      "Number of empty: 25 (4.258943781942079 %)\n",
      "Mean from number of matches: 303.05451448040884\n",
      "Median from number of matches: 10.0\n",
      "Maximal of matches: 27444\n",
      "\n",
      "NE symptom:\n",
      "Number of empty: 92 (8.984375 %)\n",
      "Mean from number of matches: 23.126953125\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "Number of empty: 62 (6.0546875 %)\n",
      "Mean from number of matches: 463.5546875\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 21785\n",
      "\n",
      "procedura:\n",
      "Number of empty: 39 (6.543624161073826 %)\n",
      "Mean from number of matches: 24.446308724832214\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 121\n",
      "Number of empty: 46 (7.718120805369128 %)\n",
      "Mean from number of matches: 936.8808724832214\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 28651\n",
      "\n",
      "\n",
      "all:\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.33927934356047\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 481.9782376025687\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n",
      "Number of empty in both search: 176\n"
     ]
    }
   ],
   "source": [
    "os_anamneza = results[results.label == \"osobní anamnéza\"]\n",
    "ne_os_anamneza = results[results.label == \"NE osobní anamnéza\"]\n",
    "medikace = results[results.label == \"medikace\"]\n",
    "ne_medikace = results[results.label == \"NE medikace\"]\n",
    "symptom = results[results.label == \"symptom\"]\n",
    "ne_symptom = results[results.label == \"NE symptom\"]\n",
    "procedura = results[results.label == \"procedura\"]\n",
    "    \n",
    "print(\"osobní anamnéza:\")    \n",
    "print_stats(os_anamneza[\"mash_search\"])\n",
    "print_stats(os_anamneza[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE osobní anamnéza:\")\n",
    "print_stats(ne_os_anamneza[\"mash_search\"])\n",
    "print_stats(ne_os_anamneza[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nmedikace:\")\n",
    "print_stats(medikace[\"mash_search\"])\n",
    "print_stats(medikace[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE medikace:\")\n",
    "print_stats(ne_medikace[\"mash_search\"])\n",
    "print_stats(ne_medikace[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nsymptom:\")\n",
    "print_stats(symptom[\"mash_search\"])\n",
    "print_stats(symptom[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE symptom:\")\n",
    "print_stats(ne_symptom[\"mash_search\"])\n",
    "print_stats(ne_symptom[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nprocedura:\")\n",
    "print_stats(procedura[\"mash_search\"])\n",
    "print_stats(procedura[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\n\\nall:\")\n",
    "print_stats(results[\"mash_search\"])\n",
    "print_stats(results[\"medvik_search_combined\"])\n",
    "print(\"Number of empty in both search:\", len(results[(results[\"mash_search\"].apply(lambda x: len(x) == 0)) & (results[\"medvik_search_combined\"].apply(lambda x: len(x) == 0))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec406b8-d613-4010-89fe-923fdb263f38",
   "metadata": {},
   "source": [
    "We can see, that most labels work quite similar to each others. One big exception is label \"medikace\" (in english medication). This label have significantly higher empty rate, but have less of matches. \n",
    "\n",
    "I this is caused by shorter text (have less of words), but these words are usually more concrete (as names of medicine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a48c2",
   "metadata": {},
   "source": [
    "### Results for Mash and Medvik search\n",
    "Now I am going to evaluate results from GPT for linking.\n",
    "\n",
    "For this I have created a sample of 100 entries, which I have send to GPT to find best match. From them I picked up another sample of 35 entries which I have evaluated manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "10a07e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "Number of empty Linking for Medvik_combined_search: 11\n",
      "Number of empty Linking for Mash_search: 10\n",
      "Number of not assigned for Medvik: 39\n",
      "Number of not assigned for Mash: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: {}\".format(len(explanation)))\n",
    "\n",
    "print(\"Number of empty Linking for Medvik_combined_search: {}\".format(explanation[\"medvik_search_combined\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of empty Linking for Mash_search: {}\".format(explanation[\"mash_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "\n",
    "print(\"Number of not assigned for Medvik: {}\".format(explanation[\"medvik_explanation\"].apply(lambda x: x is None).sum()))\n",
    "print(\"Number of not assigned for Mash: {}\".format(explanation[\"mash_explanation\"].apply(lambda x: x is None).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f61b6e-b54e-49fe-a36c-360dfe2f680c",
   "metadata": {},
   "source": [
    "We can see, that there is high number of not assigned in both searches. But in Medvik it is much higher. The higher number in Medvik is because we have to drop very long searches. In the future accesses it is important to handle the long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7629bfed-9848-4de1-b252-0add47bb4173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "asign = []\n",
    "for j in explanation.sample(35, random_state=42).index:   \n",
    "    if explanation[\"medvik_explanation\"][j] is not None:\n",
    "        x = explanation[\"medvik_explanation\"][j]\n",
    "        asign.append((explanation[\"text\"][j], \"Medvik\", \"{} ({})\".format(x[1], x[2])))\n",
    "    if explanation[\"mash_explanation\"][j] is not None:\n",
    "        x = explanation[\"mash_explanation\"][j]\n",
    "        asign.append((explanation[\"text\"][j], \"Mash\", \"{} ({})\".format(x[1], x[2])))\n",
    "    if explanation[\"mash_explanation\"][j] is None and explanation[\"medvik_explanation\"][j] is None:\n",
    "        asign.append((explanation[\"text\"][j], \"None\", \"Empty\"))\n",
    "\n",
    "i = 0\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "\n",
    "assert len(set([i[3] for i in asign])) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "da440789-4211-414e-b8a9-e1155196eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not assigned medvik: 15\n",
      "Mistakes from medvik: 13\n",
      "Partially right from medvik: 5\n",
      "Right from medvik: 2\n",
      "\n",
      "Not assigned mash: 11\n",
      "Mistakes from mash: 13\n",
      "Partially right from mash: 5\n",
      "Right from mash: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Not assigned medvik:\", 35 - len([i for i in asign if i[1] == \"Medvik\"]))\n",
    "print(\"Mistakes from medvik:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]))\n",
    "print(\"Partially right from medvik:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]))\n",
    "print(\"Right from medvik:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]))\n",
    "\n",
    "print(\"\\nNot assigned mash:\", 35 - len([i for i in asign if i[1] == \"Mash\"]))\n",
    "print(\"Mistakes from mash:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]))\n",
    "print(\"Partially right from mash:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]))\n",
    "print(\"Right from mash:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f477d6ba-305e-4d4e-ac85-b0bbb6e8a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text wrong in medvik and mash: ['MG vlevo', 'bez šelestu', 'neostře konturované ložisko 7x5mm', 'bez poruchy kinetiky myokardu', 'norm. velikost srdeč. oddílů', 'jizevnaté změny v ZDK', 'tumorozní ložisko']\n",
      "\n",
      "text wrong only in medvik ['benigní verifikované ložisko v HKK', 'játra bez solidních patologických ložiskových změn', 'USG pravé mammy a axilly', 'mírný sekund lymfedém pod axilou, v zadní axil. řase', 'apokrinní metaplazií a místy i adenóza', 'mastitis: ne']\n",
      "\n",
      "text wrong only in mash ['někdy tahv oblasti jizvy', 'subjektivně bez bolestí', 'močový měchýř hypodenzní homogenní náplně', 'bránice hladká', 'fibropleurální změny', 'dlouhodobě stac. nález']\n"
     ]
    }
   ],
   "source": [
    "med = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]\n",
    "print(\"text wrong in medvik and mash:\", [i for i in med if i in mash])\n",
    "\n",
    "print(\"\\ntext wrong only in medvik\", [i for i in med if i not in mash])\n",
    "\n",
    "print(\"\\ntext wrong only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "39fb4e68-e0dc-467f-bfc1-9d21497b0978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text partially right in medvik and mash: ['parciální mastektomie vlevo']\n",
      "\n",
      "text partially right only in medvik ['močový měchýř hypodenzní homogenní náplně', 'bránice hladká', 'zn. krvácení', 'průjmy']\n",
      "\n",
      "text partially right only in mash ['játra bez solidních patologických ložiskových změn', 'USG pravé mammy a axilly', 'uzliny fyziologické', 'operace: 0']\n"
     ]
    }
   ],
   "source": [
    "med = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]\n",
    "print(\"text partially right in medvik and mash:\", [i for i in med if i in mash])\n",
    "\n",
    "print(\"\\ntext partially right only in medvik\", [i for i in med if i not in mash])\n",
    "\n",
    "print(\"\\ntext partially right only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "818286ae-e3a6-4410-9040-b09a32cf579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text right in medvik and mash: ['parestezie nepozoruje', 'bolesti na hrudi 0', 'axilla volná', 'jaterní testy']\n",
      "\n",
      "text right only in medvik ['USG (Mamma, Axilla', 'anastrozol', 'jizva v ZHQ zhojena', 'CLEXANE']\n",
      "\n",
      "text right only in mash ['gynekologické operace']\n"
     ]
    }
   ],
   "source": [
    "med = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]\n",
    "print(\"text right in medvik and mash:\", [i for i in med if i in mash])\n",
    "\n",
    "print(\"\\ntext right only in medvik\", [i for i in med if i not in mash])\n",
    "\n",
    "print(\"\\ntext right only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26abe141",
   "metadata": {},
   "source": [
    "## Improved Access\n",
    "\n",
    "Now I am going to try another access, where I try handle former mistakes. The biggest change is not to have one list of links for whole text, but to have one list for each word from the text. And then try to explain this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "55345bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_inclusion_modified(string, func):\n",
    "    splitted_input = (string.split(\" \"))\n",
    "    lenght = len(splitted_input)\n",
    "    \n",
    "    result_dict = {}\n",
    "    for word in splitted_input:\n",
    "        result_dict[word] = []\n",
    "        \n",
    "    for j in range(1, lenght + 1):\n",
    "        splitted_dict={}\n",
    "        for elem in splitted_input:\n",
    "            splitted_dict[j] = False\n",
    "                    \n",
    "        for words in combinations(splitted_input, j):\n",
    "            data = func(\" \".join(words))\n",
    "            if len(data) == 0:\n",
    "                continue\n",
    "            for j in words:\n",
    "                splitted_dict[j] = True\n",
    "                result_dict[j] += [(i[0], i[1], words) for i in data]\n",
    "                    \n",
    "        splitted_input = [j for j, i in splitted_dict.items() if i]\n",
    "        if len(splitted_input) == 0:\n",
    "            break\n",
    "            \n",
    "    for k, v in result_dict.copy().items():\n",
    "        result_dict[k] = [i for i in v if len(i[2]) == len(v[-1][2])]\n",
    "        pop_key = True\n",
    "        for n in set([i[2] for i in result_dict[k]]):\n",
    "            string = \" \".join(n)\n",
    "            if string == k:\n",
    "                pop_key = False\n",
    "            if string in result_dict:\n",
    "                continue\n",
    "            result_dict[string] = [(i[0], i[1]) for i in result_dict[k] if \" \".join(i[2]) == string]\n",
    "            \n",
    "        if pop_key:\n",
    "            result_dict.pop(k)\n",
    "    \n",
    "    return result_dict\n",
    "        \n",
    "    \n",
    "def search_db_mash_optimized_modified(db):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(lambda x: search_with_inclusion_modified(x, mash_search))\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "828474f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_access = results[[\"text\"]].sample(100, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db336a-120b-4061-bbf7-af6c8794f39e",
   "metadata": {},
   "source": [
    "First we need to link them to databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "66620abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"saved_search/new_access.csv\"):\n",
    "    test_new_access = pd.read_csv(\"saved_search/new_access.csv\")\n",
    "    test_new_access.index = test_new_access[\"Unnamed: 0\"]\n",
    "    test_new_access.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    test_new_access[\"mash_search\"] = test_new_access[\"mash_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(from_string_to_dict)\n",
    "\n",
    "else:\n",
    "    test_new_access[\"mash_search\"] = \"N/A\"\n",
    "    for j in test_new_access.index:\n",
    "        test_new_access[\"mash_search\"][j] = search_with_inclusion_modified(test_new_access[\"text\"][j], mash_search)\n",
    "\n",
    "    test_new_access[\"medvik_search\"] = \"N/A\"\n",
    "    for j in test_new_access.index:\n",
    "        test_new_access[\"medvik_search\"][j] = search_with_inclusion_modified(test_new_access[\"text\"][j], medvik_search_combined)\n",
    "\n",
    "    test_new_access.to_csv(\"saved_search/new_access.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f652d63-5c73-49f7-b18c-3254954d47df",
   "metadata": {},
   "source": [
    "To send message to GPT we need not to exceed certain length. We try to discover some lenght, by which the medvik search returns only noice (or really probably)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "a0ba76c3-149f-469b-84ba-6221b8259d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[('vlně', 22)], [('krvácení', 23)], [('mírné', 23)], [('stomatologické', 27)], [('tlustého střeva', 30)], [('nových', 30)], [('stabilní', 32)], [('strukturou', 36)], [('laloku', 38)]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "temp = test_new_access[\"medvik_search\"].apply(lambda x: [(i, len(x[i])) for i in x if len(x[i]) > 20])\n",
    "print(sorted(list(temp[temp.apply(lambda x: len(x) != 0)]), key=(lambda x: x[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c228a-3ab2-44e5-a830-3055e1549b0a",
   "metadata": {},
   "source": [
    "We can see, that for longer length than 40 we get mostly non-medical terms (or general medical terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ccc2b105-8cbe-4bda-a4c6-51b8b70d47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_long(dictionary):\n",
    "    for key in dictionary.copy():\n",
    "        if len(dictionary[key]) > 40:\n",
    "            dictionary[key] = []\n",
    "    return dictionary\n",
    "\n",
    "test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(drop_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e97da2-c6af-4960-92b7-5721102673a8",
   "metadata": {},
   "source": [
    "The second part is to choose the best one by GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "8730f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"saved_search/new_access_explanation.csv\"):\n",
    "    test_new_access = pd.read_csv(\"saved_search/new_access_explanation.csv\")\n",
    "    test_new_access.index = test_new_access[\"Unnamed: 0\"]\n",
    "    test_new_access.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    test_new_access[\"mash_search\"] = test_new_access[\"mash_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"mash_explanation\"] = test_new_access[\"mash_explanation\"].fillna(\"{}\").apply(from_string_to_dict_to_tuple)\n",
    "    test_new_access[\"medvik_explanation\"] = test_new_access[\"medvik_explanation\"].fillna(\"{}\").apply(from_string_to_dict_to_tuple)\n",
    "\n",
    "else:   \n",
    "    test_new_access[\"medvik_explanation\"] = \"N/A\"\n",
    "    for i in test_new_access.index:\n",
    "        l = test_new_access[\"medvik_search\"][i]\n",
    "        result = {}\n",
    "        for text in l:\n",
    "            message = message_chatGPT(text, l[text], find_by_code_medvik)\n",
    "            response = send_to_chat(message)\n",
    "            result[text] = from_chatGPT(response, l[text], find_by_code_medvik)\n",
    "        test_new_access[\"medvik_explanation\"][i] = result\n",
    "\n",
    "    test_new_access[\"mash_explanation\"] = \"N/A\"\n",
    "    for i in test_new_access.index:\n",
    "        l = test_new_access[\"mash_search\"][i]\n",
    "        result = {}\n",
    "        for text in l:\n",
    "            message = message_chatGPT(text, l[text], find_by_code_medvik)\n",
    "            response = send_to_chat(message)\n",
    "            result[text] = from_chatGPT(response, l[text], find_by_code_medvik)\n",
    "        test_new_access[\"mash_explanation\"][i] = result\n",
    "\n",
    "    test_new_access.to_csv(\"saved_search/new_access_explanation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beff63c-f3e1-4d4f-80c9-3f8ccc63c97a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "3db302e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "Number of empty Linking for Medvik_combined_search: 12\n",
      "Number of empty Linking for Mash_search: 10\n",
      "Number of not assigned for Medvik: 12\n",
      "Number of not assigned for Mash: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: {}\".format(len(test_new_access)))\n",
    "\n",
    "print(\"Number of empty Linking for Medvik_combined_search: {}\".format(test_new_access[\"medvik_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of empty Linking for Mash_search: {}\".format(test_new_access[\"mash_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "\n",
    "print(\"Number of not assigned for Medvik: {}\".format(test_new_access[\"medvik_explanation\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of not assigned for Mash: {}\".format(test_new_access[\"mash_explanation\"].apply(lambda x: len(x) == 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "cf0bc563-9a28-4e77-9ee9-cfda9ebccf52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "asign = []\n",
    "for j in test_new_access.sample(35, random_state=42).index:   \n",
    "    if test_new_access[\"medvik_explanation\"][j] is not None:\n",
    "        x = test_new_access[\"medvik_explanation\"][j]\n",
    "        asign.append((test_new_access[\"text\"][j], \"Medvik\", \"{}\".format([(e, x[e]) for e in x])))\n",
    "    if test_new_access[\"mash_explanation\"][j] is not None:\n",
    "        x = test_new_access[\"mash_explanation\"][j]\n",
    "        asign.append((test_new_access[\"text\"][j], \"Mash\", \"{}\".format([(e, x[e]) for e in x])))\n",
    "    if test_new_access[\"mash_explanation\"][j] is None and test_new_access[\"medvik_explanation\"][j] is None:\n",
    "        asign.append((test_new_access[\"text\"][j], \"None\", \"Empty\"))\n",
    "\n",
    "i = 0\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "f3ecc646-3adf-4935-8a0e-32c9fd32f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not assigned medvik: 1\n",
      "Mistakes from medvik: 20\n",
      "Partially right from medvik: 6\n",
      "Right from medvik: 8\n",
      "\n",
      "Not assigned mash: 2\n",
      "Mistakes from mash: 18\n",
      "Partially right from mash: 10\n",
      "Right from mash: 5\n",
      "\n",
      "text wrong in medvik and mash: ['DKK: bez otoků', 'kličky tenkého i tlustého střeva na necíleném vyšetření přiměřeného kalibru i norm. šíře stěny', 'fibrocystické změny s mnohočetnými intraduktálními papilomy', 'beze změny zdra. satvu', 'oboustranné totální mastektomii', 'vpačování bradavek 0', 'bez patrných MTS', 'menzes no', 'mírné velikostní progresi', 'tamoxifenu', 'mamila: pravidelné stavby', 'mutace v genu NBN', 'vlevo bez patol', 'bez nových poíží']\n",
      "text wrong only in medvik ['gynekologické operace', 'AS reg', 'normě', 'váha stabilní', 'kompletní klinické regrese', 'regrese v prsu']\n",
      "text wrong only in mash ['parc. ME s disekcí axily', 'anastrozol', 'jizva v ZHQ zhojena', 'neurotoxicita']\n",
      "\n",
      "text partially right in medvik and mash: ['kůže intaktní', 'stolice spíš zácpovitá', 'hysterectomii pro krvácení', 'klinicky lipom při sternu', 'GIT toxicita G1']\n",
      "text partially right only in medvik ['parc. ME s disekcí axily']\n",
      "text partially right only in mash ['USG (Mamma, Axilla', 'váha stabilní', 'kompletní klinické regrese', 'regrese v prsu', 'CLEXANE']\n",
      "\n",
      "text right in medvik and mash: ['parestezie nepozoruje', 'bolesti na hrudi 0', 'axilla volná', 'jaterní testy']\n",
      "text right only in medvik ['USG (Mamma, Axilla', 'anastrozol', 'jizva v ZHQ zhojena', 'CLEXANE']\n",
      "text right only in mash ['gynekologické operace']\n"
     ]
    }
   ],
   "source": [
    "print(\"Not assigned medvik:\", len([i for i in asign if i[1] == \"Medvik\" and i[3] == \"\"]))\n",
    "print(\"Mistakes from medvik:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]))\n",
    "print(\"Partially right from medvik:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]))\n",
    "print(\"Right from medvik:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]))\n",
    "\n",
    "print(\"\\nNot assigned mash:\", len([i for i in asign if i[1] == \"Mash\" and i[3] == \"\"]))\n",
    "print(\"Mistakes from mash:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]))\n",
    "print(\"Partially right from mash:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]))\n",
    "print(\"Right from mash:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]))\n",
    "\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext wrong in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text wrong only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text wrong only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext partially right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text partially right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text partially right only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text right only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b64ca9-d3d4-414d-aa22-53dd2cf8b645",
   "metadata": {},
   "source": [
    "I have noticed, that most of the words which have been linked correctly have been in basic form (Sg 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf637de3-c82d-4f2f-9aaf-dc888c8bed43",
   "metadata": {},
   "source": [
    "#### Some Adititional comments on results\n",
    "During labeling I noticed, that there can be problem with punctuation (because of punctuation we usualy don't find match). We try to discover if there is some punctuation we can remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "c8425d22-341f-4b66-bb50-ea8cdc2f8a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'', ',', ',(', ',+./', '-', '.', '.-', ':'}"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_new_access[\"text\"].apply(lambda x: \"\".join(set([i for i in x if i in punctuation]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "1829ede5-bb1a-46d2-a764-0d161f51780f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patterns: ',('\n",
      "('(Mamma,', 0) : USG (Mamma, Axilla\n",
      "('vlevo,', 0) : patní ostruha vlevo, po podání rázové vlny\n",
      "('denzitometir,', 0) : denzitometir, e\n",
      "('71/reg,', 0) : sr. 71/reg, osa + 9, převodní časy v normě, QTc 414 mm, bez ložisk. ischem změn\n",
      "('břicho,', 0) : břicho, měkké, prohmanté, nebol\n",
      "('hepar,', 0) : hepar, lien nehmatám\n",
      "\n",
      "Patterns: ':'\n",
      "('mamila:', 0) : mamila: pravidelné stavby\n",
      "('DKK:', 0) : DKK: bez otoků\n",
      "('FA:', 0) : FA: sine\n",
      "\n",
      "Patterns: '-/+'\n",
      "('kolene-', 0) : kolene- Baker. cysta\n",
      "('tru-cut', 0) : st. p. tru-cut biopsii\n",
      "('COVID-19', 4) : příznaky COVID-19 nevykazuje\n",
      "('-', 0) : NACT - paclitaxel weekly\n",
      "('-', 0) : mammy - vpravo jizva po ablaci\n",
      "('71/reg,', 0) : sr. 71/reg, osa + 9, převodní časy v normě, QTc 414 mm, bez ložisk. ischem změn\n",
      "\n",
      "Patterns: '.'\n",
      "('zdra.', 5) : beze změny zdra. satvu\n",
      "('ovar.', 0) : prezervace oocytů pomocí ovar. ablace\n",
      "('patol.', 0) : kůže bez patol. efloresc\n",
      "('hmat.', 1) : bez hmat. patol. resistence\n",
      "('bilat.', 0) : homans bilat. negat\n",
      "('neoadj.', 0) : neoadj. léčba herceptinem\n",
      "('Baker.', 0) : kolene- Baker. cysta\n",
      "('l.', 0) : TAD axillae l. sin. No. I\n",
      "('stp.', 0) : stp. operaci žlučníku\n",
      "('st.', 8) : st. p. tru-cut biopsii\n",
      "('norm.', 1) : kličky tenkého i tlustého střeva na necíleném vyšetření přiměřeného kalibru i norm. šíře stěny\n",
      "('susp.', 2) : susp. uzlina v pravé axila\n",
      "('parc.', 0) : parc. ME s disekcí axily\n",
      "('patol.', 0) : bez patol. lymfadenopatie\n",
      "('nadkl.', 0) : axila a nadkl. 0\n",
      "('solit.', 0) : susp solit. MTS\n",
      "('st.', 0) : st. p. parc. ME s disekcí axily\n",
      "('sr.', 0) : sr. 71/reg, osa + 9, převodní časy v normě, QTc 414 mm, bez ložisk. ischem změn\n",
      "('alv.', 0) : dýchání alv. čisté\n"
     ]
    }
   ],
   "source": [
    "print(\"Patterns: ',('\")\n",
    "pattern = \",(\"\n",
    "for i in test_new_access[test_new_access[\"text\"].apply(lambda x: any([i in pattern  for i in x]))].index:\n",
    "    text = test_new_access.loc[i][\"text\"]\n",
    "    search = test_new_access.loc[i][\"medvik_search\"]\n",
    "    print([(x, len(search.get(x, []))) for x in text.split(\" \") if any([True for l in x if l in pattern])][0], \":\", text)\n",
    "\n",
    "print(\"\\nPatterns: ':'\")\n",
    "pattern = \":\"\n",
    "for i in test_new_access[test_new_access[\"text\"].apply(lambda x: any([i in pattern  for i in x]))].index:\n",
    "    text = test_new_access.loc[i][\"text\"]\n",
    "    search = test_new_access.loc[i][\"medvik_search\"]\n",
    "    print([(x, len(search.get(x, []))) for x in text.split(\" \") if any([True for l in x if l in pattern])][0], \":\", text)\n",
    "\n",
    "print(\"\\nPatterns: '-/+'\")\n",
    "pattern = \"-/+\"\n",
    "for i in test_new_access[test_new_access[\"text\"].apply(lambda x: any([i in pattern  for i in x]))].index:\n",
    "    text = test_new_access.loc[i][\"text\"]\n",
    "    search = test_new_access.loc[i][\"medvik_search\"]\n",
    "    print([(x, len(search.get(x, []))) for x in text.split(\" \") if any([True for l in x if l in pattern])][0], \":\", text)\n",
    "\n",
    "print(\"\\nPatterns: '.'\")\n",
    "pattern = \".\"\n",
    "for i in test_new_access[test_new_access[\"text\"].apply(lambda x: any([i in pattern  for i in x]))].index:\n",
    "    text = test_new_access.loc[i][\"text\"]\n",
    "    search = test_new_access.loc[i][\"medvik_search\"]\n",
    "    print([(x, len(search.get(x, []))) for x in text.split(\" \") if any([True for l in x if l in pattern])][0], \":\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18bb7c-ed7e-4242-bdcc-b68c1a3994a0",
   "metadata": {},
   "source": [
    "We can see, that comma and parenthesis have no specific meaning, so we can remove them. \n",
    "\n",
    "On the other hand colon has specific meaning, its meaning is specifing some cathegory and the rest from the text is about it.\n",
    "\n",
    "The others punctuations have specific meaning. For example dot, which specify that the word is only shorcut or dash which is part of some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "e52435d1-6136-4e27-af6d-48c63d20d6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uzliny: fyziologické\n",
      "antikoncepce: 0\n",
      "operace: 0\n",
      "alergie: Ketazon urtika\n",
      "alergie: Červená paprika a kočky\n",
      "břicho: v niveau\n",
      "alergie: O\n",
      "DKK:O\n",
      "ložiska: l.dx. ZDK solitární 6x6x5 mm\n",
      "gynekologická onemocnění: ne\n",
      "operace: krční mandle\n",
      "mastitis: neguje\n",
      "perikard:bez výpotku\n",
      "mastitis: ne\n",
      "plíce: poklep plný jasný\n",
      "gynekologické operace: 0\n",
      "dušnost: 0\n",
      "srdce: as reg\n",
      "uzliny: patologické\n",
      "hlava : poklepově nebolestivá\n",
      "hormonální léčba: 0\n",
      "axila i nadkl:O\n",
      "karnofsky index: 100\n",
      "alergie: neuvádí\n",
      "břicho: měkké\n",
      "mastitis: 0\n",
      "hormonální léčba: HA + HRT\n",
      "hormonální léčba: HRT\n",
      "ITP: 1\n",
      "alergie: 0\n",
      "antikoncepce: cca 2roky\n",
      "hormonální léčba: HRT dříve\n",
      "DKK: bez otoků\n",
      "trávicí potíže: 0\n",
      "gynekologická onemocnění: 0\n",
      "gynekologické operace: neguje\n",
      "DKK :hybnost volná v plném rozsahu\n",
      "gynekologické operace: ne\n",
      "uzliny: nejsou patrné\n",
      "axilly: 0\n",
      "krk: nápln žil v normě\n",
      "antikoncepce: IUD jaydess\n",
      "FA: sine\n",
      "ao: trojcípá\n",
      "operace: neguje\n",
      "uzliny: suspektní\n",
      "OPERACE: Mastectomia part. l. sin\n",
      "cyklus: pravidelný\n",
      "gynekologická onemocnění: neguje\n",
      "O ITP: O\n",
      "alergie: srsti zátěžová\n",
      "GA: porody O\n",
      "mamila: pravidelné stavby\n",
      "břicho:měkké\n",
      "břicho : v niveau\n",
      "břicho:měkké prohm\n",
      "DKK: volně pohybl\n",
      "operace: ITP\n",
      "COVID anamn: negat\n",
      "parestezie: 0\n",
      "alergie: furantoin\n",
      "menarché: 11\n",
      "gynekolog. operace: O\n",
      "AA: ne\n",
      "kůže: čistá\n",
      "re : bez patolog. nálezu\n",
      "abortus: O\n",
      "AA:0\n"
     ]
    }
   ],
   "source": [
    "data_improved_punctuation = data.copy()\n",
    "data_improved_punctuation[\"original_text\"] = data[\"text\"]\n",
    "data_improved_punctuation[\"text\"] = data_improved_punctuation[\"text\"].apply(\n",
    "    lambda text: \" \".join([word.strip(\" ,()\") for word in text.split(\" \")]))\n",
    "\n",
    "for i in data_improved_punctuation.index:\n",
    "    if len(data_improved_punctuation[\"text\"][i].split(\":\")) >= 2:\n",
    "        print(data_improved_punctuation[\"text\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8ebb1-e012-4018-9eca-2b0513bcc9d6",
   "metadata": {},
   "source": [
    "During solving the colon problem I noticed, that there is another meaning of colon. Sometimes it was together at the end with 0. Its meaning is negation. There are also other ways how to express negation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "81d68ba9-04d7-49ab-a7b9-0f06ab373617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antikoncepce: 0\n",
      "operace: 0\n",
      "gynekologické operace: 0\n",
      "dušnost: 0\n",
      "hormonální léčba: 0\n",
      "mastitis: 0\n",
      "alergie: 0\n",
      "trávicí potíže: 0\n",
      "gynekologická onemocnění: 0\n",
      "axilly: 0\n",
      "parestezie: 0\n",
      "AA:0\n",
      "\n",
      "astma 0\n",
      "bolesti na hrudi 0\n",
      "antikoncepce: 0\n",
      "dušnost - 0 - bez obtíží\n",
      "operace: 0\n",
      "arytmie 0\n",
      "IM 0\n",
      "bolest - 0 - žádná\n",
      "thyreopatie 0\n",
      "DM 0\n",
      "axile bez evid patol uzlin nadklíček 0\n",
      "gynekologická onemocnění: ne\n",
      "axila a nadkl. 0\n",
      "TT 0\n",
      "palpitace a stenokardie 0\n",
      "zvracení - 0 - nezvrací\n",
      "nadklíček 0\n",
      "zvracení - 0 - nezvracíí\n",
      "regurgitace 0\n",
      "slabost nebo únava 0\n",
      "infekce 0\n",
      "hepar a lien 0\n",
      "otoky DKK 0\n",
      "transfuze 0\n",
      "mastitis: ne\n",
      "ŠŽ 0\n",
      "gynekologické operace: 0\n",
      "CHOPN 0\n",
      "DVT 0\n",
      "dušnost: 0\n",
      "dušnost ani kašel také ne\n",
      "dušnost - 0\n",
      "VCHGD 0\n",
      "hormonální léčba: 0\n",
      "vpačování bradavek 0\n",
      "mastitis: 0\n",
      "žádná dušnost - 0\n",
      "dušnosta kašel 0\n",
      "axila 0\n",
      "CMP 0\n",
      "TBC 0\n",
      "alergie: 0\n",
      "TEN 0\n",
      "dušnosta akšel 0\n",
      "vředová choroba 0\n",
      "gynekologické potíže 0\n",
      "trávicí potíže: 0\n",
      "gynekologická onemocnění: 0\n",
      "výtoky z bradavek 0\n",
      "gynekologické operace: ne\n",
      "kašel 0\n",
      "axilly: 0\n",
      "pálení žáhy 0\n",
      "potraty 0 indukované\n",
      "krev ve stolici 0\n",
      "zvracení - 0\n",
      "bez otoku zarudnutí sekrece 0\n",
      "PS 0\n",
      "nadýmání 0\n",
      "sekrece 0\n",
      "uzliny 0\n",
      "meléna 0\n",
      "onemocnění jater a ledvin 0\n",
      "bolest - 0\n",
      "bolest - 0 - žádná dušnost - 0 - bez obtíží zvracení - 0 - nezvrací\n",
      "krvácení 0\n",
      "parestezie: 0\n",
      "AA: ne\n",
      "pS 0\n",
      "říhání  pálení žáhy 0\n",
      "axila a nadklíček 0\n"
     ]
    }
   ],
   "source": [
    "for i in data_improved_punctuation.index:\n",
    "    colon_split = data_improved_punctuation[\"text\"][i].split(\":\")\n",
    "    if len(colon_split) >= 2 and colon_split[1].strip(\" \") == \"0\":\n",
    "        print(data_improved_punctuation[\"text\"][i])\n",
    "print()\n",
    "for i in data_improved_punctuation.index:\n",
    "    words_split = data_improved_punctuation[\"text\"][i].split(\" \")\n",
    "    if any([True for x in words_split if x.strip(\" \") in [\"0\", \"ne\"]]):\n",
    "        print(data_improved_punctuation[\"text\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f23bfc-d7c3-4015-9c03-1ace8bdedd0e",
   "metadata": {},
   "source": [
    "Now we remove the negation from there and create new colomn for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "288b66c4-ab6f-4ba4-8e4c-5bb65038e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_improved_punctuation[\"negation\"] = False\n",
    "for i in data_improved_punctuation.index:\n",
    "    colon_split = data_improved_punctuation[\"text\"][i].split(\":\")\n",
    "    if len(colon_split) >= 2 and colon_split[1].strip(\" \") in  [\"0\", \"ne\", \"O\"]:\n",
    "        data_improved_punctuation.at[i, \"negation\"] = True\n",
    "        data_improved_punctuation.at[i, \"text\"] = colon_split[0]\n",
    "for i in data_improved_punctuation.index:\n",
    "    words_split = data_improved_punctuation[\"text\"][i].split(\" \")\n",
    "    if any([True for x in words_split if x.strip(\" \") in [\"0\", \"ne\"]]):\n",
    "        data_improved_punctuation.at[i, \"negation\"] = True\n",
    "        data_improved_punctuation.at[i, \"text\"] = \" \".join([x for x in words_split if x not in [\"0\", \"ne\"]])\n",
    "    # If there is bez on the beginning, it is mostly related to whole text, but in the middle of the text\n",
    "    # it can only be related to part of it\n",
    "    elif words_split[0].strip(\" \") == \"bez\":\n",
    "        data_improved_punctuation.at[i, \"negation\"] = True\n",
    "        data_improved_punctuation.at[i, \"text\"] = \" \".join(words_split[1:])\n",
    "\n",
    "data_improved_punctuation[\"about\"] = \"N/A\"\n",
    "for i in data_improved_punctuation.index:\n",
    "    colon_split = data_improved_punctuation[\"text\"][i].split(\":\")\n",
    "    if len(colon_split) >= 2:\n",
    "        data_improved_punctuation.at[i, \"about\"] = colon_split[0].strip(\" \")\n",
    "        data_improved_punctuation.at[i, \"text\"] = colon_split[1].strip(\" \")\n",
    "\n",
    "data_improved_punctuation[\"text\"] = data_improved_punctuation[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "2bb74024-a37b-4d8c-986c-d2ecdee0bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>original_text</th>\n",
       "      <th>negation</th>\n",
       "      <th>about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                          text                 original_text  \\\n",
       "0    symptom        jemný fibrózní proužek        jemný fibrózní proužek   \n",
       "1  procedura             neoadjuvantní CHT             neoadjuvantní CHT   \n",
       "2   medikace                      novalgin                      novalgin   \n",
       "3    symptom     označena SLU v levé axile     označena SLU v levé axile   \n",
       "4  procedura  st.p. totální ME + SNB vlevo  st.p. totální ME + SNB vlevo   \n",
       "\n",
       "   negation about  \n",
       "0     False   N/A  \n",
       "1     False   N/A  \n",
       "2     False   N/A  \n",
       "3     False   N/A  \n",
       "4     False   N/A  "
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_improved_punctuation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff65af-4844-4bed-b6b5-a0fa1d0e9da2",
   "metadata": {},
   "source": [
    "## Improved Search with preprocessing\n",
    "Because we have noticed, that in previous model it worked well for words which have been in basic form. We try to preprocess all words this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f64b3-3be5-4f53-8665-1e7cf77d7d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a537ce0-f625-4479-8952-b93163a50ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fedee-b63b-4ca9-a089-09d2e6767da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "5031eda2-c6c0-4b5a-8899-9f7569de027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>original_text</th>\n",
       "      <th>negation</th>\n",
       "      <th>about</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>symptom</td>\n",
       "      <td>hypovit D</td>\n",
       "      <td>hypovit D</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6024</th>\n",
       "      <td>symptom</td>\n",
       "      <td>velikostní progresi</td>\n",
       "      <td>velikostní progresi</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6026</th>\n",
       "      <td>symptom</td>\n",
       "      <td>DKK brnění prstů</td>\n",
       "      <td>DKK brnění prstů</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>procedura</td>\n",
       "      <td>nukleární medicína</td>\n",
       "      <td>nukleární medicína</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>medikace</td>\n",
       "      <td>herceptin sc 3weekly</td>\n",
       "      <td>herceptin sc 3weekly</td>\n",
       "      <td>False</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2803 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                          text                 original_text  \\\n",
       "0       symptom        jemný fibrózní proužek        jemný fibrózní proužek   \n",
       "1     procedura             neoadjuvantní CHT             neoadjuvantní CHT   \n",
       "2      medikace                      novalgin                      novalgin   \n",
       "3       symptom     označena SLU v levé axile     označena SLU v levé axile   \n",
       "4     procedura  st.p. totální ME + SNB vlevo  st.p. totální ME + SNB vlevo   \n",
       "...         ...                           ...                           ...   \n",
       "6017    symptom                     hypovit D                     hypovit D   \n",
       "6024    symptom           velikostní progresi           velikostní progresi   \n",
       "6026    symptom              DKK brnění prstů              DKK brnění prstů   \n",
       "6031  procedura            nukleární medicína            nukleární medicína   \n",
       "6032   medikace          herceptin sc 3weekly          herceptin sc 3weekly   \n",
       "\n",
       "      negation about  \n",
       "0        False   N/A  \n",
       "1        False   N/A  \n",
       "2        False   N/A  \n",
       "3        False   N/A  \n",
       "4        False   N/A  \n",
       "...        ...   ...  \n",
       "6017     False   N/A  \n",
       "6024     False   N/A  \n",
       "6026     False   N/A  \n",
       "6031     False   N/A  \n",
       "6032     False   N/A  \n",
       "\n",
       "[2803 rows x 5 columns]"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_improved_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a580178-c80d-43a0-bac8-e3908fdea724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d0101-1cf6-43b1-9c9a-9ff23594235d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74350b-066c-4a41-86c8-76e034ea24ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "a64af8ba-ae44-468f-ab47-60ef84a24f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_access_whole_way(string):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
