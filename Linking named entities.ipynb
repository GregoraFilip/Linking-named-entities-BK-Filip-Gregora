{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec09843",
   "metadata": {},
   "source": [
    "# Linking named entities\n",
    "Filip Gregora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06c163ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/NER_entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c62645ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>Novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>Označena SLU v levé axile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      Novalgin\n",
       "3     symptom    Označena SLU v levé axile.\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             Založení TE l.sin\n",
       "7   procedura                   Cytostatika\n",
       "8  NE symptom         přiměřené echogenity,\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6678d27",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "At the beginning we want to explore data.\n",
    "\n",
    "- We can see that somewhere there is big letter at the beginning (but be carefull when whole first word is written in upper case)\n",
    "- Somewhere at the end is interpuncion\n",
    "- There are lots of duplicates\n",
    "- the length of text is variable and the longest has 20 words (this can be problem in the future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f247a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2588"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b494df98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      novalgin\n",
       "3     symptom     označena SLU v levé axile\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             založení TE l.sin\n",
       "7   procedura                   cytostatika\n",
       "8  NE symptom          přiměřené echogenity\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def clean_db(db):\n",
    "    db_copy = db.copy()\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(lambda x: x.strip(\" \" + \"\".join(punctuation)))\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(lambda x: x[0].lower() + x[1:] if x[1].islower() else x)\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(lambda x: \" \".join(x.split())) #to replace multiple whitespaces with one\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].drop_duplicates()\n",
    "    return db_copy.dropna()\n",
    "\n",
    "data = clean_db(data)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e9bc06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1 | 2: 3 | 3: 7 | 4: 15 | 5: 31 | 6: 63 | 7: 127 | 8: 255 | 9: 511 | 10: 1023 | 11: 2047 | 12: 4095 | 13: 8191 | 14: 16383 | 15: 32767 | 16: 65535 | 17: 131071 | 18: 262143 | 19: 524287 | 20: 1048575 | "
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def comb_sum(j):\n",
    "    sum = 0\n",
    "    for i in range(j, 0, -1):\n",
    "        sum += math.comb(j,i)\n",
    "\n",
    "    return sum\n",
    "\n",
    "for i in range(1, 21):\n",
    "    print(i, comb_sum(i), sep = \": \", end = \" | \")\n",
    "    \n",
    "lenght_data = data[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "len(lenght_data[lenght_data >= 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27f521ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom = data[data.label == \"symptom\"].drop([\"label\"], axis=1)\n",
    "procedura = data[data.label == \"procedura\"].drop([\"label\"], axis=1)\n",
    "medikace = data[data.label == \"medikace\"].drop([\"label\"], axis=1)\n",
    "ne_symptom = data[data.label == \"NE symptom\"].drop([\"label\"], axis=1)\n",
    "os_anamneza = data[data.label == \"osobní anamnéza\"].drop([\"label\"], axis=1)\n",
    "ne_os_anamneza = data[data.label == \"NE osobní anamnéza\"].drop([\"label\"], axis=1)\n",
    "ne_medikace = data[data.label == \"NE medikace\"].drop([\"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc5bbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(os_anamneza) + len(symptom) + len(procedura) + len(medikace) + len(ne_symptom) + len(ne_os_anamneza) + len(ne_medikace) \\\n",
    "            == len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc45a11",
   "metadata": {},
   "source": [
    "## Linking to international MASH through NIH\n",
    "Mash is international medical databaze: https://uts.nlm.nih.gov/uts/.\n",
    "\n",
    "I tried search all combinations of words from text in databaze. The longer combinations have higher priority. \n",
    "\n",
    "There is one big problem, the complexity grows exponentially with the lenght of the words (in the worst case for lenght of 20 we have to try around 10^6 combinations). My solution for this problem is go from bottom up, start with lenght 1 and continue only with combinations which success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97cd1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not search in databaze if it number or it is too short (shorter than 2)\n",
    "def filter_short(string):\n",
    "    return len(string) < 2 or string.isdigit()\n",
    "    \n",
    "    \n",
    "def print_stats(data_list):\n",
    "    empty = len(data_list[data_list.apply(lambda x: len(x) == 0)])\n",
    "    print(f\"Number of empty: {empty} ({empty / len(data_list) * 100} %)\")\n",
    "\n",
    "    number_of_matches = data_list.apply(lambda x: len(x))\n",
    "    print(f\"Mean from number of matches: {number_of_matches.mean()}\")\n",
    "    print(f\"Median from number of matches: {number_of_matches.median()}\")\n",
    "    print(f\"Maximal of matches: {number_of_matches.max()}\")\n",
    "    \n",
    "    \n",
    "def from_string_to_list(string):\n",
    "    result = []\n",
    "    for j in string.strip(\"[]()\").split(\"), (\"):\n",
    "        if len(j) == 0:\n",
    "            continue\n",
    "        result.append(tuple(j.strip(\"'\").split(\"', '\")))\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01b15b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C0149756', 'Fasciitis, Plantar')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "def mash_search_basic(string):\n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    for j in range(len(splitted_input), 0, -1):\n",
    "        for string in combinations(splitted_input, j): \n",
    "            if filter_short(\" \".join(string)):\n",
    "                continue\n",
    "                \n",
    "            path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "            query = {\n",
    "                     'string': \" \".join(string),\n",
    "                     'apiKey':'6a290909-c0d8-4db9-b531-7387929b334e',\n",
    "            }\n",
    "            res = requests.get(path, params=query)\n",
    "\n",
    "            if res.status_code <= 200:\n",
    "                data = json.loads(res.text)\n",
    "                for j in data[\"result\"][\"results\"]:\n",
    "                    result.append((j[\"ui\"], j[\"name\"]))\n",
    "            else:\n",
    "                print(res.status_code, res.text)\n",
    "        \n",
    "        if len(result) != 0:\n",
    "            break\n",
    "                        \n",
    "    return result\n",
    "        \n",
    "    \n",
    "def search_with_inclusion(string, func, output_state = False):\n",
    "    if (output_state):\n",
    "        global count\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    last_result = []\n",
    "    lenght = len(splitted_input)\n",
    "    \n",
    "    for j in range(1, lenght + 1):\n",
    "        splitted_dict={}\n",
    "        for elem in splitted_input:\n",
    "            splitted_dict[j] = False\n",
    "                    \n",
    "        for words in combinations(splitted_input, j):\n",
    "            data = func(\" \".join(words))\n",
    "            if len(data) != 0:\n",
    "                for j in words:\n",
    "                    splitted_dict[j] = True\n",
    "                if filter_short(\" \".join(words)):\n",
    "                    continue\n",
    "                result.append(data)\n",
    "\n",
    "        splitted_input = [j for j, i in splitted_dict.items() if i]\n",
    "        if len(splitted_input) == 0:\n",
    "            break\n",
    "        else:\n",
    "            last_result, result = result, []\n",
    "        \n",
    "    temp = []\n",
    "    for j in last_result:\n",
    "        temp += list(enumerate(j))\n",
    "    return [j for (i, j) in sorted(temp)]\n",
    "    \n",
    "    \n",
    "def mash_search(string):\n",
    "    path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "    query = {\n",
    "             'string': string,\n",
    "             'apiKey':'6a290909-c0d8-4db9-b531-7387929b334e',\n",
    "    }\n",
    "    res = requests.get(path, params=query)\n",
    "\n",
    "    if res.status_code <= 200:\n",
    "        data = json.loads(res.text)          \n",
    "        return [(j[\"ui\"], j[\"name\"]) for j in data[\"result\"][\"results\"]]\n",
    "    else:\n",
    "        print(res.status_code, res.text)\n",
    "        return []\n",
    "    \n",
    "\n",
    "def search_db(db, func):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(func)\n",
    "    return db \n",
    "    \n",
    "    \n",
    "def search_db_mash(db):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(mash_search_basic)\n",
    "    return db    \n",
    "\n",
    "\n",
    "def search_db_mash_optimized(db):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(lambda x: search_with_inclusion(x, mash_search))\n",
    "    return db\n",
    "\n",
    "print(mash_search_basic('bolesti patní ostruhy vlevo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5939f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osobní anamnéza:\n",
      "Number of empty: 23 (10.74766355140187 %)\n",
      "Mean from number of matches: 20.83177570093458\n",
      "Median from number of matches: 19.5\n",
      "Maximal of matches: 86\n",
      "\n",
      "NE osobní anamnéza:\n",
      "Number of empty: 4 (6.557377049180328 %)\n",
      "Mean from number of matches: 20.852459016393443\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 75\n",
      "\n",
      "\n",
      "medikace:\n",
      "Number of empty: 74 (24.262295081967213 %)\n",
      "Mean from number of matches: 14.177049180327868\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 82\n",
      "\n",
      "NE medikace:\n",
      "Number of empty: 1 (6.25 %)\n",
      "Mean from number of matches: 19.3125\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 50\n",
      "\n",
      "\n",
      "symptom:\n",
      "Number of empty: 36 (6.132879045996593 %)\n",
      "Mean from number of matches: 23.340715502555366\n",
      "Median from number of matches: 22.0\n",
      "Maximal of matches: 125\n",
      "\n",
      "NE symptom:\n",
      "Number of empty: 113 (11.03515625 %)\n",
      "Mean from number of matches: 22.505859375\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "\n",
      "procedura:\n",
      "Number of empty: 47 (7.885906040268456 %)\n",
      "Mean from number of matches: 24.10234899328859\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 121\n",
      "\n",
      "\n",
      "All Data:\n",
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(\"saved_search/os_anamneza_mash.csv\"):\n",
    "    os_anamneza_mash = pd.read_csv(\"saved_search/os_anamneza_mash.csv\")\n",
    "    os_anamneza_mash.index = os_anamneza_mash[\"Unnamed: 0\"]\n",
    "    os_anamneza_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    os_anamneza_mash[\"search\"] = os_anamneza_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    os_anamneza_mash = search_db_mash_optimized(os_anamneza)\n",
    "    os_anamneza_mash.to_csv(\"saved_search/os_anamneza_mash.csv\")\n",
    "    \n",
    "if os.path.isfile(\"saved_search/ne_os_anamneza_mash.csv\"):\n",
    "    ne_os_anamneza_mash = pd.read_csv(\"saved_search/ne_os_anamneza_mash.csv\")\n",
    "    ne_os_anamneza_mash.index = ne_os_anamneza_mash[\"Unnamed: 0\"]\n",
    "    ne_os_anamneza_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    ne_os_anamneza_mash[\"search\"] = ne_os_anamneza_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    ne_os_anamneza_mash = search_db_mash_optimized(ne_os_anamneza)\n",
    "    ne_os_anamneza_mash.to_csv(\"saved_search/ne_os_anamneza_mash.csv\")    \n",
    "\n",
    "if os.path.isfile(\"saved_search/medikace_mash.csv\"):\n",
    "    medikace_mash = pd.read_csv(\"saved_search/medikace_mash.csv\")\n",
    "    medikace_mash.index = medikace_mash[\"Unnamed: 0\"]\n",
    "    medikace_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    medikace_mash[\"search\"] = medikace_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    medikace_mash = search_db_mash_optimized(medikace)\n",
    "    medikace_mash.to_csv(\"saved_search/medikace_mash.csv\")  \n",
    "    \n",
    "if os.path.isfile(\"saved_search/ne_medikace_mash.csv\"):\n",
    "    ne_medikace_mash = pd.read_csv(\"saved_search/ne_medikace_mash.csv\")\n",
    "    ne_medikace_mash.index = ne_medikace_mash[\"Unnamed: 0\"]\n",
    "    ne_medikace_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    ne_medikace_mash[\"search\"] = ne_medikace_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    ne_medikace_mash = search_db_mash_optimized(ne_medikace)\n",
    "    ne_medikace_mash.to_csv(\"saved_search/ne_medikace_mash.csv\")    \n",
    "    \n",
    "if os.path.isfile(\"saved_search/symptom_mash.csv\"):\n",
    "    symptom_mash = pd.read_csv(\"saved_search/symptom_mash.csv\")\n",
    "    symptom_mash.index = symptom_mash[\"Unnamed: 0\"]\n",
    "    symptom_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    symptom_mash[\"search\"] = symptom_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    symptom_mash = search_db_mash_optimized(symptom)\n",
    "    symptom_mash.to_csv(\"saved_search/symptom_mash.csv\")\n",
    "    \n",
    "if os.path.isfile(\"saved_search/ne_symptom_mash.csv\"):\n",
    "    ne_symptom_mash = pd.read_csv(\"saved_search/ne_symptom_mash.csv\")\n",
    "    ne_symptom_mash.index = ne_symptom_mash[\"Unnamed: 0\"]\n",
    "    ne_symptom_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    ne_symptom_mash[\"search\"] = ne_symptom_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    ne_symptom_mash = search_db_mash_optimized(ne_symptom)\n",
    "    ne_symptom_mash.to_csv(\"saved_search/ne_symptom_mash.csv\")\n",
    "    \n",
    "if os.path.isfile(\"saved_search/procedura_mash.csv\"):\n",
    "    procedura_mash = pd.read_csv(\"saved_search/procedura_mash.csv\")\n",
    "    procedura_mash.index = procedura_mash[\"Unnamed: 0\"]\n",
    "    procedura_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    procedura_mash[\"search\"] = procedura_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    procedura_mash = search_db_mash_optimized(procedura)\n",
    "    procedura_mash.to_csv(\"saved_search/procedura_mash.csv\")\n",
    "    \n",
    "data_mash = pd.concat([ne_os_anamneza_mash, ne_medikace_mash, ne_symptom_mash, symptom_mash, os_anamneza_mash, medikace_mash, procedura_mash])\n",
    "data_mash = data_mash.sort_index()\n",
    "    \n",
    "    \n",
    "print(\"osobní anamnéza:\")    \n",
    "print_stats(os_anamneza_mash[\"search\"])\n",
    "print(\"\\nNE osobní anamnéza:\")\n",
    "print_stats(ne_os_anamneza_mash[\"search\"])\n",
    "print(\"\\n\\nmedikace:\")\n",
    "print_stats(medikace_mash[\"search\"])\n",
    "print(\"\\nNE medikace:\")\n",
    "print_stats(ne_medikace_mash[\"search\"])\n",
    "print(\"\\n\\nsymptom:\")\n",
    "print_stats(symptom_mash[\"search\"])\n",
    "print(\"\\nNE symptom:\")\n",
    "print_stats(ne_symptom_mash[\"search\"])\n",
    "print(\"\\n\\nprocedura:\")\n",
    "print_stats(procedura_mash[\"search\"])\n",
    "\n",
    "print(\"\\n\\nAll Data:\")\n",
    "print_stats(data_mash[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef10f4",
   "metadata": {},
   "source": [
    "### Not assigned\n",
    "If we look at the random sample of 10 texts, which are not assigned, then we can see that in five of them there is typographical mistake (*\"nejsou zn.plicní hpertenze\"* = *\"nejsou zn. plicní hypertenze\"*, *\"kumulce a nehomogenity\"* = *\"kumulace a nehomogenita\"*, *\"ceriucal\"* = *\"cerucal\"*, *\"paitace\"* = *\"palpitace\"*, *\"mamily klidné\"* = ?). Others five are correct medical term, but in some non-typical grammatical form.\n",
    "\n",
    "If we try to improve them we get 50 % improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a153e3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>nejsou zn. plicní hypertenze</td>\n",
       "      <td>[(C0020542, Pulmonary Hypertension), (C0152171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>hormostenické</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>kumulace a nehomogenita</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>biopsie</td>\n",
       "      <td>[(C0005558, Biopsy), (C0220797, biopsy charact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>chemobioterapie</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>dysmorfické</td>\n",
       "      <td>[(C0005887, Body Dysmorphic Disorders)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>anikterické</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>cerucal</td>\n",
       "      <td>[(C0701450, Cerucal)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>palpitace</td>\n",
       "      <td>[(C0030252, Palpitations), (C0549267, Palpitat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>mamily klidné</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  \\\n",
       "Unnamed: 0                                 \n",
       "878         nejsou zn. plicní hypertenze   \n",
       "91                         hormostenické   \n",
       "5240             kumulace a nehomogenita   \n",
       "3728                             biopsie   \n",
       "1125                     chemobioterapie   \n",
       "2479                         dysmorfické   \n",
       "4981                         anikterické   \n",
       "1134                             cerucal   \n",
       "5089                           palpitace   \n",
       "1129                       mamily klidné   \n",
       "\n",
       "                                                       search  \n",
       "Unnamed: 0                                                     \n",
       "878         [(C0020542, Pulmonary Hypertension), (C0152171...  \n",
       "91                                                         []  \n",
       "5240                                                       []  \n",
       "3728        [(C0005558, Biopsy), (C0220797, biopsy charact...  \n",
       "1125                                                       []  \n",
       "2479                  [(C0005887, Body Dysmorphic Disorders)]  \n",
       "4981                                                       []  \n",
       "1134                                    [(C0701450, Cerucal)]  \n",
       "5089        [(C0030252, Palpitations), (C0549267, Palpitat...  \n",
       "1129                                                       []  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_sample = data_mash[data_mash[\"search\"].apply(lambda x: len(x) == 0)].sample(10, random_state=42)\n",
    "\n",
    "# Because of my mistake (I had worser clean_db), the code above generate different sample than I have worked with.\n",
    "# So I have to create the sample by hand:\n",
    "empty_sample = data_mash.loc[[878, 91, 5240, 3728, 1125, 2479, 4981, 1134, 5089, 1129]]\n",
    "\n",
    "empty_sample[\"text\"][878] = \"nejsou zn. plicní hypertenze\"\n",
    "empty_sample[\"text\"][91] = \"hormostenické\"\n",
    "empty_sample[\"text\"][5240] = \"kumulace a nehomogenita\"\n",
    "empty_sample[\"text\"][3728] = \"biopsie\"\n",
    "empty_sample[\"text\"][1125] = \"chemobioterapie\"\n",
    "empty_sample[\"text\"][2479] = \"dysmorfické\"\n",
    "empty_sample[\"text\"][4981] = \"anikterické\"\n",
    "empty_sample[\"text\"][1134] = \"cerucal\"\n",
    "empty_sample[\"text\"][5089] = \"palpitace\"\n",
    "empty_sample[\"text\"][1129] = \"mamily klidné\"\n",
    "\n",
    "empty_sample = search_db_mash_optimized(empty_sample)\n",
    "empty_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a45dc4",
   "metadata": {},
   "source": [
    "There is one mistake which we can correct automaticly and it is not having space after punctuation mark. We can see that if we have space after punctuation then it find something, else it didn't.\n",
    "\n",
    "We can see that there is around 150 examples of this mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9881b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(search_with_inclusion(\"zn. plicní\", mash_search)))\n",
    "print(len(search_with_inclusion(\"zn.plicní\", mash_search)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ede5ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            return False\n",
    " \n",
    "    return True\n",
    "\n",
    "def insert_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            string = string[:i+1] + \" \" + string[i+1:]\n",
    " \n",
    "    return string\n",
    "\n",
    "no_space = data[~data[\"text\"].apply(is_space_after_punc)]\n",
    "len(no_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0f2ba076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.383517659650373\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "data_mash[\"label\"] = \"N/A\"\n",
    "for i in data_mash.index:\n",
    "    data_mash[\"label\"][i] = data[\"label\"][i]\n",
    "\n",
    "if os.path.isfile(\"saved_search/data_mash_inserted_space.csv\"):\n",
    "    inserted_space_data_mash = pd.read_csv(\"saved_search/data_mash_inserted_space.csv\")\n",
    "    inserted_space_data_mash.index = inserted_space_data_mash[\"Unnamed: 0\"]\n",
    "    inserted_space_data_mash.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    inserted_space_data_mash[\"search\"] = inserted_space_data_mash[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    inserted_space_data_mash = data_mash.copy()\n",
    "    no_space[\"text\"] = no_space[\"text\"].apply(insert_space_after_punc)\n",
    "    for i in no_space.index:\n",
    "        inserted_space_data_mash[\"search\"][i] = search_with_inclusion(no_space[\"text\"][i], mash_search)\n",
    "        inserted_space_data_mash[\"text\"][i] = no_space[\"text\"][i]\n",
    "    inserted_space_data_mash.to_csv(\"saved_search/data_mash_inserted_space.csv\")    \n",
    "        \n",
    "print_stats(data_mash[\"search\"])\n",
    "print()\n",
    "print_stats(inserted_space_data_mash[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25133cb",
   "metadata": {},
   "source": [
    "Thanks to this upgrade we improved search by find 40 new matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03172cc",
   "metadata": {},
   "source": [
    "## Linking to CZ Mash through Medvik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6d500763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as elt\n",
    "import re\n",
    "\n",
    "content = elt.parse('databaze/MeSH2023_Marc21_Alma.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fbaf7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternize(string):\n",
    "    result = []\n",
    "    for i in string:\n",
    "        if i in '<([{\\\\^-=$!|]})?*+.>]':\n",
    "            result.append(\"\\\\\" + i)\n",
    "        else:\n",
    "            result.append(i)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def medvik_search(string, init_pattern, last_pattern):\n",
    "    result = []\n",
    "    pattern = re.compile(f\"{init_pattern}{patternize(string)}{last_pattern}\",re.IGNORECASE)\n",
    "    \n",
    "    for child in content:\n",
    "        for subchild in child.iter(\"{http://www.loc.gov/MARC21/slim}subfield\"):\n",
    "            if subchild.text and pattern.match(subchild.text) is not None:\n",
    "                try:\n",
    "                    code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "                    name = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"150\" ][0][0].text\n",
    "                    result.append((code, name))\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    break                \n",
    "    return result\n",
    "\n",
    "\n",
    "def medvik_search_match(string):\n",
    "    return medvik_search(string, \".*\", \".*\")\n",
    "\n",
    "\n",
    "def medvik_search_exact(string):              \n",
    "    return medvik_search(string, \"^\", \"$\")\n",
    "\n",
    "\n",
    "def medvik_search_words(string):      \n",
    "    return medvik_search(string, \".* \", \" .*\")\n",
    "\n",
    "\n",
    "def medvik_search_combined(string):\n",
    "    result = medvik_search(string, \"^\", \"$\")\n",
    "    if len(result) == 0:\n",
    "        result = medvik_search(string, \".* \", \" .*\")\n",
    "    if len(result) == 0:\n",
    "        result = medvik_search(string, \".*\", \".*\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def search_db_medvik_match(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_match, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_exact(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_exact, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_words(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_words, output_state=True))\n",
    "\n",
    "\n",
    "def search_db_medvik_combined(db):\n",
    "    return search_db(db, lambda x: search_with_inclusion(x, medvik_search_combined, output_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "56ec8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.383517659650373\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_mash_medvik.csv\"):\n",
    "    data_mash_medvik = pd.read_csv(\"saved_search/data_mash_medvik.csv\")\n",
    "    data_mash_medvik.index = data_mash_medvik[\"Unnamed: 0\"]\n",
    "    data_mash_medvik.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    data_mash_medvik[\"search\"] = data_mash_medvik[\"search\"].apply(from_string_to_list)\n",
    "    data_mash_medvik[\"search_medvik\"] = data_mash_medvik[\"search_medvik\"].apply(from_string_to_list)\n",
    "    data_mash_medvik = data_mash_medvik.rename(columns={\"search\": \"search_mash\"})\n",
    "else:\n",
    "    count = 0\n",
    "    data_mash_medvik = data_mash_medvik.rename(columns={\"search\": \"search_mash\"})\n",
    "    data_mash_medvik = search_db_medvik_match(inserted_space_data_mash)\n",
    "    data_mash_medvik.to_csv(\"saved_search/data_mash_medvik.csv\")\n",
    "    data_mash_medvik = data_mash_medvik.rename(columns={\"search\": \"search_medvik\"})\n",
    "    \n",
    "print_stats(data_mash_medvik[\"search_mash\"])\n",
    "print()\n",
    "print_stats(data_mash_medvik[\"search_medvik\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6567ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "1562     1904\n",
      "1469     1720\n",
      "2438        0\n",
      "5068    27715\n",
      "2433     1722\n",
      "894        94\n",
      "212         9\n",
      "1221    10724\n",
      "4394        0\n",
      "5457      112\n",
      "Name: search_medvik, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_mash_medvik[\"search_medvik\"].apply(lambda x: len(x)).sample(10, random_state=42))\n",
    "\n",
    "print()\n",
    "temp = data_mash_medvik[\"search_medvik\"].apply(lambda x: len(x))\n",
    "len(temp[temp > 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2418733",
   "metadata": {},
   "source": [
    "We can see, that some examples are working properly. On the other hand we have really lots of samples whose lenght grows exponentially.\n",
    "\n",
    "For this reasons it might be better to use exact match instead of contains match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53dd6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 2265.2\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 27715\n",
      "\n",
      "Words match\n",
      "Number of empty: 6 (30.0 %)\n",
      "Mean from number of matches: 194.0\n",
      "Median from number of matches: 5.5\n",
      "Maximal of matches: 1918\n",
      "\n",
      "Exact match\n",
      "Number of empty: 11 (55.00000000000001 %)\n",
      "Mean from number of matches: 3.05\n",
      "Median from number of matches: 0.0\n",
      "Maximal of matches: 22\n",
      "\n",
      "Combined match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 261.95\n",
      "Median from number of matches: 6.5\n",
      "Maximal of matches: 1904\n"
     ]
    }
   ],
   "source": [
    "test_data = data_mash.sample(20, random_state=42)\n",
    "\n",
    "if os.path.isfile(\"saved_search/test_medvik.csv\"):\n",
    "    test_data = pd.read_csv(\"saved_search/test_medvik.csv\")\n",
    "    test_data[\"search_match\"] = test_data[\"search_match\"].apply(from_string_to_list)\n",
    "    test_data[\"search_exact\"] = test_data[\"search_exact\"].apply(from_string_to_list)\n",
    "    test_data[\"search_words\"] = test_data[\"search_words\"].apply(from_string_to_list)\n",
    "    test_data[\"search_combined\"] = test_data[\"search_combined\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    test_data[\"search_match\"] = search_db_medvik_match(test_data)[\"search\"]\n",
    "    test_data[\"search_exact\"] = search_db_medvik_exact(test_data)[\"search\"]\n",
    "    test_data[\"search_words\"] = search_db_medvik_words(test_data)[\"search\"]\n",
    "    test_data[\"search_combined\"] = search_db_medvik_combined(test_data)[\"search\"]\n",
    "    test_data.to_csv(\"saved_search/test_medvik.csv\")\n",
    "    \n",
    "print(\"Contains match\")\n",
    "print_stats(test_data[\"search_match\"])\n",
    "print(\"\\nWords match\")\n",
    "print_stats(test_data[\"search_words\"])\n",
    "print(\"\\nExact match\")\n",
    "print_stats(test_data[\"search_exact\"])\n",
    "print(\"\\nCombined match\")\n",
    "print_stats(test_data[\"search_combined\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9b5a0",
   "metadata": {},
   "source": [
    "We can see that using exact match we get rid of the long matches but it have quite low success rate. Using words match is something in the middle (not good in both ways).\n",
    "\n",
    "As last option we used combined match (first try exact, if don't success then words, then only match). This seems as the best methods (this doesn't create too large lists and has the same number of empty matches as contains match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "05709eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"saved_search/data_mash_medvik_combined.csv\"):\n",
    "    data_mash_medvik_combined = pd.read_csv(\"saved_search/data_mash_medvik_combined.csv\")\n",
    "    data_mash_medvik_combined.index = data_mash_medvik_combined[\"Unnamed: 0\"]\n",
    "    data_mash_medvik_combined.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    data_mash_medvik_combined[\"search_mash\"] = data_mash_medvik_combined[\"search_mash\"].apply(from_string_to_list)\n",
    "    data_mash_medvik_combined[\"search_medvik\"] = data_mash_medvik_combined[\"search_medvik\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    data_mash_medvik_combined = inserted_space_data_mash.rename(columns={\"search\": \"search_mash\"})\n",
    "    data_mash_medvik_combined = search_db_medvik_combined(data_mash_medvik_combined)\n",
    "    data_mash_medvik_combined = data_mash_medvik_combined.rename(columns={\"search\": \"search_medvik\"})\n",
    "    data_mash_medvik_combined.to_csv(\"saved_search/data_mash_medvik_combined.csv\")\n",
    "    \n",
    "    \n",
    "print_stats(data_mash_medvik_combined[\"search_medvik\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4d23d",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "It is possible to get duplicates in list of matches, when getting the same match from two different words from text.\n",
    "\n",
    "So I will remove them and observe how it change results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "25363344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inserted_space_data_mash[~inserted_space_data_mash[\"search\"].apply(lambda x: len(set(x)) == len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d2e0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.383517659650373\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n",
      "\n",
      "\n",
      "After removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.33927934356047\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1625.7213699607564\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 29327\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 481.9782376025687\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "def remove_dup_preserve_order(l):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in l if not (x in seen or seen_add(x))]\n",
    "\n",
    "print(\"Before removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_stats(data_mash_medvik[\"search_mash\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_stats(data_mash_medvik[\"search_medvik\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_stats(data_mash_medvik_combined[\"search_medvik\"])\n",
    "\n",
    "data_mash_medvik[\"search_mash\"] = data_mash_medvik[\"search_mash\"].apply(remove_dup_preserve_order)\n",
    "data_mash_medvik[\"search_medvik\"] = data_mash_medvik[\"search_medvik\"].apply(remove_dup_preserve_order)\n",
    "data_mash_medvik_combined[\"search_mash\"] = data_mash_medvik[\"search_mash\"]\n",
    "data_mash_medvik_combined[\"search_medvik\"] = data_mash_medvik_combined[\"search_medvik\"].apply(remove_dup_preserve_order)\n",
    "\n",
    "print(\"\\n\\nAfter removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_stats(data_mash_medvik[\"search_mash\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_stats(data_mash_medvik[\"search_medvik\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_stats(data_mash_medvik_combined[\"search_medvik\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
