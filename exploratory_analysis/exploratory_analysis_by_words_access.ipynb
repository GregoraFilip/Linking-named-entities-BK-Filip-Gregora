{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec09843",
   "metadata": {},
   "source": [
    "# Linking named entities\n",
    "by Filip Gregora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c163ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from string import punctuation, ascii_letters\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import xml.etree.ElementTree as elt\n",
    "from openai import OpenAI\n",
    "import regex\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62645ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>Novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>Označena SLU v levé axile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      Novalgin\n",
       "3     symptom    Označena SLU v levé axile.\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             Založení TE l.sin\n",
       "7   procedura                   Cytostatika\n",
       "8  NE symptom         přiměřené echogenity,\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/NER_entities.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f247a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2588"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b494df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6034 -> 2803 : 3231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      novalgin\n",
       "3     symptom     označena SLU v levé axile\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             založení TE l.sin\n",
       "7   procedura                   cytostatika\n",
       "8  NE symptom          přiměřené echogenity\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(string):\n",
    "    string = string.strip(\" \" + \"\".join(punctuation))\n",
    "    # Remove first upper letter if not all letters are upper\n",
    "    if len(string) >= 2:\n",
    "        string = string[0].lower() + string[1:] if string[1].islower() else string\n",
    "    # Replace multiple whitespaces with one\n",
    "    return \" \".join(string.split())\n",
    "\n",
    "def clean_table(db):\n",
    "    db_copy = db.copy()\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(clean)\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].drop_duplicates()\n",
    "    return db_copy.dropna()\n",
    "\n",
    "former_len = len(data)\n",
    "data = clean_table(data)\n",
    "print(former_len, \"->\", len(data), \":\", former_len - len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb7a63-1b02-4215-9063-9a24cfddbe18",
   "metadata": {},
   "source": [
    "\n",
    "### Linking to international MESH through NIH\n",
    "Mash is international medical databaze: https://uts.nlm.nih.gov/uts/.\n",
    "\n",
    "I tried search all combinations of words from text in databaze. The longer combinations have higher priority. \n",
    "\n",
    "There is one big problem, the complexity grows exponentially with the lenght of the words (in the worst case for lenght of 20 we have to try around 10^6 combinations). My solution for this problem is go from bottom up, start with lenght 1 and continue only with combinations which success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cd1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not search in databaze if it number or it is too short (shorter than 2)\n",
    "def filter_short(string):\n",
    "    return len(string) < 2 or string.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d79706-d8f6-4d8c-9268-4936a0cdaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From string to list which contains tuples\n",
    "def from_string_to_list(string):\n",
    "    result = []\n",
    "    for j in string.strip(\"[]()\").split(\"), (\"):\n",
    "        if len(j) == 0:\n",
    "            continue\n",
    "        result.append(tuple([s.strip(\"'\\\" \\\\\") for s in j.split(\"', \")]))\n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "#From string to tuple\n",
    "def from_string_to_tuple(string):\n",
    "    if string == \"N/A\":\n",
    "        return\n",
    "    string = string.strip(\"\\\\\\\" '\")\n",
    "    stripped_string = string[0].strip(\"(\") + string[1:-1] + string[-1].strip(\")\")\n",
    "    \n",
    "    result = [i.strip(\"\\\\\\\"'\") for i in stripped_string.split(\", \")]\n",
    "    return (result[0], result[1], \", \".join(result[2:]))\n",
    "\n",
    "\n",
    "#From string to dictionary\n",
    "def from_string_to_dict(string):\n",
    "    result = {}\n",
    "    for j in string.strip(\"{} \").split(\"], \"):\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        i = list(j.split(\": [\"))\n",
    "        assert len(i) == 2\n",
    "        result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_list(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#From string to dictionary which contains tuples\n",
    "def from_string_to_dict_to_tuple(string):\n",
    "    result = {}\n",
    "    for j in regex.split(\"(\\)| None), ('|\\\")\", string.strip(\"{} \")):\n",
    "        if j in [\"\", ')', ' None', \"'\", '\"']:\n",
    "            continue\n",
    "        i = list(j.split(\": (\"))\n",
    "        if len(i) == 1:\n",
    "            i[0] = i[0].split(\": None\")[0].strip(\": \")\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = None\n",
    "        else:\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_tuple(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "#From string to dictionary with ints\n",
    "from_string_to_int_dict = (lambda x: {elem.split(\"': \")[0].strip(\"' \\\"\") : int(elem.split(\"': \")[1])\n",
    "                                      for elem in x.strip(\"{}\\\"' \").split(\", '\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d500763",
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_mshcz = elt.parse('../databaze/MeSH2023_Marc21_Alma.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbaf7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medvik_search(string, test):\n",
    "    result = []\n",
    "    for child in offline_mshcz:\n",
    "        for subchild in child.iter(\"{http://www.loc.gov/MARC21/slim}subfield\"):\n",
    "            if subchild.text and test(string, subchild.text):\n",
    "                try:\n",
    "                    code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "                    name = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"150\" ][0][0].text\n",
    "                    result.append((code, name))\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    break                \n",
    "    return result\n",
    "\n",
    "\n",
    "def medvik_exact_search(string):              \n",
    "    return medvik_search(string, lambda x, y: x.lower() == y.lower())\n",
    "\n",
    "\n",
    "def medvik_words_search(string):      \n",
    "    return medvik_search(string, lambda x, y: (\" \" + x.lower() + \" \") in y.lower())\n",
    "\n",
    "\n",
    "def medvik_match_search(string):\n",
    "    return medvik_search(string, lambda x, y: x.lower() in y.lower())\n",
    "\n",
    "\n",
    "def medvik_combined_search(string):\n",
    "    result = medvik_exact_search(string)\n",
    "    if len(result) == 0:\n",
    "        result = medvik_words_search(string)\n",
    "    if len(result) == 0:\n",
    "        result = medvik_match_search(string)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2177a4b",
   "metadata": {},
   "source": [
    "## Choosing best match with Chat GPT\n",
    "The idea behind our model is first link term to database and then choose the best one by some pretrained language model.\n",
    "\n",
    "I use GPT-3.5, because it is free to access with limitations (There are some limits of access per day. And there is limited number of access per account. Then we have to pay.), it is fast and it is well known.\n",
    "\n",
    "The message to GPT is in this format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5917d",
   "metadata": {},
   "source": [
    "Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \"[MEDICAL TERM]\":\n",
    "\n",
    "    1. [DESCRIPTION_N.1] (pojem: [TERM_N.1])\n",
    "    2. [DESCRIPTION_N.2] (pojem: [TERM_N.2])\n",
    "    ...\n",
    "    \n",
    "Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a818507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medvik_find_by_code(string):\n",
    "    if len(string) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    for child in offline_mshcz:\n",
    "        try:\n",
    "            code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "            if code == string:\n",
    "                d = [i.iter(\"{http://www.loc.gov/MARC21/slim}subfield\") for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"680\"][0]\n",
    "                return next(d).text\n",
    "        except IndexError:\n",
    "            continue      \n",
    "            \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17707115",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../APIkeys/NIH\", \"r\") as f:\n",
    "    NIH_api = f.read()\n",
    "\n",
    "def send_to_GPT(message):\n",
    "    if message == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    with open(\"../APIkeys/chatGTP\", \"r\") as f:\n",
    "        chatgpt_api = f.read()\n",
    "\n",
    "    client = OpenAI(api_key=chatgpt_api)\n",
    "    return client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-16k\",\n",
    "                messages=[{\"role\": \"user\", \"content\": message}],\n",
    "                stream=False)\n",
    "\n",
    "\n",
    "def message_for_GPT(string, li, find, context=None):\n",
    "    if len(li) == 0:\n",
    "        return \"\"\n",
    "            \n",
    "    if context is None:\n",
    "        result = [f\"Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \\\"{string}\\\":\\n\"]\n",
    "    else:\n",
    "        result = [f\"Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \\\"{string}\\\" v kontextu:  \\\"{context}\\\":\\n\"]\n",
    "        \n",
    "    j = 1\n",
    "    for i in li:\n",
    "        result.append(f\"{j}. {find(i[0])} (pojem: {i[1]})\\n\")\n",
    "        j += 1\n",
    "        \n",
    "    result.append(\"Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE. Pokud to není lékařský pojem odpověz taky NONE.\")\n",
    "    \n",
    "    return \"\".join(result)\n",
    "    \n",
    "def find_int(string):\n",
    "    result = []\n",
    "    for i in string:\n",
    "        if i.isdigit():\n",
    "            result.append(i)\n",
    "\n",
    "    return int(\"\".join(result))\n",
    "\n",
    "\n",
    "def from_GPT(result, li, find):\n",
    "    try:\n",
    "        i = find_int(result.choices[0].message.content) - 1\n",
    "        return (li[i][0], li[i][1], find(li[i][0]))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26abe141",
   "metadata": {},
   "source": [
    "## Improved Search\n",
    "\n",
    "Now I am going to try another access, where I try handle former mistakes. The biggest change is not to have one list of links for whole text, but to have one list for each word from the text. And then try to explain this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55345bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_from_bottom_no_drop(string, func):\n",
    "    splitted_input = (string.split(\" \"))\n",
    "    lenght = len(splitted_input)\n",
    "    \n",
    "    result_dict = {}\n",
    "    for word in splitted_input:\n",
    "        result_dict[word] = []\n",
    "        \n",
    "    for j in range(1, lenght + 1):\n",
    "        splitted_dict={}\n",
    "        for elem in splitted_input:\n",
    "            splitted_dict[j] = False\n",
    "                    \n",
    "        for words in combinations(splitted_input, j):\n",
    "            data = func(\" \".join(words))\n",
    "            if len(data) == 0:\n",
    "                continue\n",
    "            for j in words:\n",
    "                splitted_dict[j] = True\n",
    "                result_dict[j] += [(i[0], i[1], words) for i in data]\n",
    "                    \n",
    "        splitted_input = [j for j, i in splitted_dict.items() if i]\n",
    "        if len(splitted_input) == 0:\n",
    "            break\n",
    "            \n",
    "    for k, v in result_dict.copy().items():\n",
    "        result_dict[k] = [i for i in v if len(i[2]) == len(v[-1][2])]\n",
    "        pop_key = True\n",
    "        for n in set([i[2] for i in result_dict[k]]):\n",
    "            string = \" \".join(n)\n",
    "            if string == k:\n",
    "                pop_key = False\n",
    "            if string in result_dict:\n",
    "                continue\n",
    "            result_dict[string] = [(i[0], i[1]) for i in result_dict[k] if \" \".join(i[2]) == string]\n",
    "            \n",
    "        if pop_key:\n",
    "            result_dict.pop(k)\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db336a-120b-4061-bbf7-af6c8794f39e",
   "metadata": {},
   "source": [
    "First we need to link them to databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66620abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../saved_search/new_access.csv\"):\n",
    "    test_new_access = pd.read_csv(\"../saved_search/new_access.csv\")\n",
    "    test_new_access.index = test_new_access[\"Unnamed: 0\"]\n",
    "    test_new_access.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    test_new_access[\"mash_search\"] = test_new_access[\"mash_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(from_string_to_dict)\n",
    "\n",
    "else:\n",
    "    test_new_access = results[[\"text\"]].sample(100, random_state=25)\n",
    "    test_new_access[\"mash_search\"] = \"N/A\"\n",
    "    for j in test_new_access.index:\n",
    "        test_new_access[\"mash_search\"][j] = search_from_bottom_no_drop(test_new_access[\"text\"][j], mash_search)\n",
    "\n",
    "    test_new_access[\"medvik_search\"] = \"N/A\"\n",
    "    for j in test_new_access.index:\n",
    "        test_new_access[\"medvik_search\"][j] = search_from_bottom_no_drop(test_new_access[\"text\"][j], medvik_combined_search)\n",
    "\n",
    "    test_new_access.to_csv(\"../saved_search/new_access.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f652d63-5c73-49f7-b18c-3254954d47df",
   "metadata": {},
   "source": [
    "To send message to GPT we need not to exceed certain length. We try to discover some lenght, by which the medvik search returns only noice (or really probably)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ba76c3-149f-469b-84ba-6221b8259d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('vlně', 22)], [('krvácení', 23)], [('mírné', 23)], [('stomatologické', 27), ('vyš', 874)], [('nových', 30)], [('stabilní', 32)], [('strukturou', 36)], [('laloku', 38)], [('susp', 52)], [('i na', 58), ('tlustého střeva', 30)], [('operace', 58)], [('nebol', 66)], [('léčí s', 76)], [('spíš', 77)], [('příl', 84)], [('e', 95)], [('genetické', 99)], [('p.', 119)], [('NACT', 128), ('-', 5334)], [('plicní', 162)], [('klinické', 164)], [('ME s', 166)], [('ME s', 166)], [('léčba', 181)], [('vyšetření', 186)], [('příznaky', 314)], [('není', 327)], [('TAD', 331), ('l. I', 72)], [('- po', 386)], [('pomocí', 393)], [('pm', 548)], [('PM', 548), ('se', 7588)], [('negat', 740)], [('Cor', 1304)], [('patol', 6932)], [('v', 7248)], [('toxicita', 11218)], [('v', 14496)]]\n"
     ]
    }
   ],
   "source": [
    "def print_long_searches(db, limit=20):\n",
    "    temp = db.apply(lambda x: [(i, len(x[i])) for i in x if len(x[i]) > limit])\n",
    "    print(sorted(list(temp[temp.apply(lambda x: len(x) != 0)]), key=(lambda x: x[0][1])))\n",
    "\n",
    "print_long_searches(test_new_access[\"medvik_search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c228a-3ab2-44e5-a830-3055e1549b0a",
   "metadata": {},
   "source": [
    "We can see, that for longer length than 40 we get mostly non-medical terms (or general medical terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc2b105-8cbe-4bda-a4c6-51b8b70d47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_long_searches(dictionary, limit=40):\n",
    "    for key in dictionary.copy():\n",
    "        if len(dictionary[key]) > limit:\n",
    "            dictionary[key] = []\n",
    "    return dictionary\n",
    "\n",
    "test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(drop_long_searches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e97da2-c6af-4960-92b7-5721102673a8",
   "metadata": {},
   "source": [
    "The second part is to choose the best one by GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8730f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../saved_search/new_access_explanation.csv\"):\n",
    "    test_new_access = pd.read_csv(\"../saved_search/new_access_explanation.csv\")\n",
    "    test_new_access.index = test_new_access[\"Unnamed: 0\"]\n",
    "    test_new_access.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    test_new_access[\"mash_search\"] = test_new_access[\"mash_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"medvik_search\"] = test_new_access[\"medvik_search\"].apply(from_string_to_dict)\n",
    "    test_new_access[\"mash_explanation\"] = test_new_access[\"mash_explanation\"].fillna(\"{}\").apply(from_string_to_dict_to_tuple)\n",
    "    test_new_access[\"medvik_explanation\"] = test_new_access[\"medvik_explanation\"].fillna(\"{}\").apply(from_string_to_dict_to_tuple)\n",
    "\n",
    "else:   \n",
    "    test_new_access[\"medvik_explanation\"] = \"N/A\"\n",
    "    for i in test_new_access.index:\n",
    "        l = test_new_access[\"medvik_search\"][i]\n",
    "        result = {}\n",
    "        for text in l:\n",
    "            message = message_for_GPT(text, l[text], medvik_find_by_code)\n",
    "            response = send_to_GPT(message)\n",
    "            result[text] = from_GPT(response, l[text], medvik_find_by_code)\n",
    "        test_new_access[\"medvik_explanation\"][i] = result\n",
    "\n",
    "    test_new_access[\"mash_explanation\"] = \"N/A\"\n",
    "    for i in test_new_access.index:\n",
    "        l = test_new_access[\"mash_search\"][i]\n",
    "        result = {}\n",
    "        for text in l:\n",
    "            message = message_for_GPT(text, l[text], medvik_find_by_code)\n",
    "            response = send_to_GPT(message)\n",
    "            result[text] = from_GPT(response, l[text], medvik_find_by_code)\n",
    "        test_new_access[\"mash_explanation\"][i] = result\n",
    "\n",
    "    test_new_access.to_csv(\"../saved_search/new_access_explanation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beff63c-f3e1-4d4f-80c9-3f8ccc63c97a",
   "metadata": {},
   "source": [
    "### Results\n",
    "Now its time to examine the results of improved search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db302e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "Number of empty Linking for Medvik_combined_search: 12\n",
      "Number of empty Linking for Mash_search: 10\n",
      "Number of not assigned for Medvik: 12\n",
      "Number of not assigned for Mash: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: {}\".format(len(test_new_access)))\n",
    "\n",
    "print(\"Number of empty Linking for Medvik_combined_search: {}\".format(test_new_access[\"medvik_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of empty Linking for Mash_search: {}\".format(test_new_access[\"mash_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "\n",
    "print(\"Number of not assigned for Medvik: {}\".format(test_new_access[\"medvik_explanation\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of not assigned for Mash: {}\".format(test_new_access[\"mash_explanation\"].apply(lambda x: len(x) == 0).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011872e-aca0-4f52-b85a-6ab9af9f3611",
   "metadata": {},
   "source": [
    "There we have got much more better results than in basic access. We were able to choose the best match for nearly everything, what we have been able to find in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf0bc563-9a28-4e77-9ee9-cfda9ebccf52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "asign = []\n",
    "for j in test_new_access.sample(35, random_state=42).index:   \n",
    "    if test_new_access[\"medvik_explanation\"][j] is not None:\n",
    "        x = test_new_access[\"medvik_explanation\"][j]\n",
    "        asign.append((test_new_access[\"text\"][j], \"Medvik\", \"{}\".format([(e, x[e]) for e in x])))\n",
    "    if test_new_access[\"mash_explanation\"][j] is not None:\n",
    "        x = test_new_access[\"mash_explanation\"][j]\n",
    "        asign.append((test_new_access[\"text\"][j], \"Mash\", \"{}\".format([(e, x[e]) for e in x])))\n",
    "    if test_new_access[\"mash_explanation\"][j] is None and test_new_access[\"medvik_explanation\"][j] is None:\n",
    "        asign.append((test_new_access[\"text\"][j], \"None\", \"Empty\"))\n",
    "\n",
    "i = 0\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e115b7-92d4-4f1f-9e13-4164f6a3f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not assigned medvik: 1\n",
      "Mistakes from medvik: 20\n",
      "Partially right from medvik: 6\n",
      "Right from medvik: 8\n",
      "\n",
      "Not assigned mash: 2\n",
      "Mistakes from mash: 18\n",
      "Partially right from mash: 10\n",
      "Right from mash: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Not assigned medvik:\", len([i for i in asign if i[1] == \"Medvik\" and i[3] == \"\"]))\n",
    "print(\"Mistakes from medvik:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]))\n",
    "print(\"Partially right from medvik:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]))\n",
    "print(\"Right from medvik:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]))\n",
    "\n",
    "print(\"\\nNot assigned mash:\", len([i for i in asign if i[1] == \"Mash\" and i[3] == \"\"]))\n",
    "print(\"Mistakes from mash:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]))\n",
    "print(\"Partially right from mash:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]))\n",
    "print(\"Right from mash:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b76d8-09d0-44fe-a572-76ee6322f874",
   "metadata": {},
   "source": [
    "The results are better than previous access:\n",
    "\n",
    "For medvik we have got 40 % for at least partially right linking. And 23 % for completely right linking.\n",
    "\n",
    "For mash we have got 43 % for at least partially right linking. And 14 % for completely right linking.\n",
    "\n",
    "But even these results are very good, they need next improvement. For this reason I would like to try another improved linking. But first I look at the wrong, partially and right results and observe if there is some pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3ecc646-3adf-4935-8a0e-32c9fd32f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text wrong in medvik and mash: ['DKK: bez otoků', 'kličky tenkého i tlustého střeva na necíleném vyšetření přiměřeného kalibru i norm. šíře stěny', 'fibrocystické změny s mnohočetnými intraduktálními papilomy', 'beze změny zdra. satvu', 'oboustranné totální mastektomii', 'vpačování bradavek 0', 'bez patrných MTS', 'menzes no', 'mírné velikostní progresi', 'tamoxifenu', 'mamila: pravidelné stavby', 'mutace v genu NBN', 'vlevo bez patol', 'bez nových poíží']\n",
      "text wrong only in medvik ['gynekologické operace', 'AS reg', 'normě', 'váha stabilní', 'kompletní klinické regrese', 'regrese v prsu']\n",
      "text wrong only in mash ['parc. ME s disekcí axily', 'anastrozol', 'jizva v ZHQ zhojena', 'neurotoxicita']\n",
      "\n",
      "text partially right in medvik and mash: ['kůže intaktní', 'stolice spíš zácpovitá', 'hysterectomii pro krvácení', 'klinicky lipom při sternu', 'GIT toxicita G1']\n",
      "text partially right only in medvik ['parc. ME s disekcí axily']\n",
      "text partially right only in mash ['USG (Mamma, Axilla', 'váha stabilní', 'kompletní klinické regrese', 'regrese v prsu', 'CLEXANE']\n",
      "\n",
      "text right in medvik and mash: ['parestezie nepozoruje', 'bolesti na hrudi 0', 'axilla volná', 'jaterní testy']\n",
      "text right only in medvik ['USG (Mamma, Axilla', 'anastrozol', 'jizva v ZHQ zhojena', 'CLEXANE']\n",
      "text right only in mash ['gynekologické operace']\n"
     ]
    }
   ],
   "source": [
    "med = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]\n",
    "print(\"text wrong in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text wrong only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text wrong only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext partially right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text partially right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text partially right only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text right only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b64ca9-d3d4-414d-aa22-53dd2cf8b645",
   "metadata": {},
   "source": [
    "- I have noticed, that most of the words which have been linked correctly have been in basic form (Sg 1).\n",
    "- Some from the wrong one have mistake or there a punctuation is doing some mess.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf637de3-c82d-4f2f-9aaf-dc888c8bed43",
   "metadata": {},
   "source": [
    "### Some Adititional comments on results\n",
    "The results above aren't pretty good. Some changes and improvements can be done in the medical text. But lots of these changes will be label specific.\n",
    "\n",
    "During labeling I have noticed, that there can be problem with punctuation (because of punctuation we usualy don't find match). For this reason I tried to discover if there is some punctuation we can remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8425d22-341f-4b66-bb50-ea8cdc2f8a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'%', '(', ')', '+', ',', '-', '.', '/', ':', ';', '['}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_in_data = set()\n",
    "data[\"text\"].apply(lambda x: punc_in_data.update(set([i for i in x if i in punctuation])))\n",
    "punc_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1829ede5-bb1a-46d2-a764-0d161f51780f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation: %\n",
      "ki 100%, aloepcie,sliznice prokrveny, oběh. komp\n",
      "ki 100%,alopecie,sliznice prokrveny, oběh. komp\n",
      "inf. glucosi 10% 500 ml\n",
      "růst trabekulárně, solidně, s polarizací do 10 %, jádra s jemným chromatinem\n",
      "KI 100% lucidní\n",
      "\n",
      "Punctuation: (\n",
      "proliferace dle Ki67 (automat) 35\n",
      "RTG (Plíce\n",
      "cílenou axilární disekcí (SNB + klipovaná uzlina\n",
      "biopsie sentinelové uzliny (SNB\n",
      "vyrážka na kůži (kopřivka\n",
      "re-resekce - laterální části (kůže + podkoží) + disekce pravé axily - en bloc\n",
      "adjuvantní radioterapii na hrudní stěnu vpravo + axilu vpravo ( I-IV.etáž\n",
      "páteře C+ L( diskopatie\n",
      "USG (Břicho\n",
      "alergie: Ketazon (urtika\n",
      "\n",
      "Punctuation: )\n",
      "proliferace dle Ki67 (automat) 35\n",
      "odstranění klipované (a ev. sentinelové) uzliny\n",
      "re-resekce - laterální části (kůže + podkoží) + disekce pravé axily - en bloc\n",
      "\n",
      "Punctuation: +\n",
      "adjuv CHt paclitaxel weekly 12x + trastuzuab\n",
      "ko + trombo + dif\n",
      "LHRH+IA\n",
      "H+L nehmatné\n",
      "hye+ae\n",
      "UZ+MMG\n",
      "totální ME + SNB vlevo\n",
      "cílenou axilární disekcí (SNB + klipovaná uzlina\n",
      "LDK, st.p. HYE+AE\n",
      "páteře C+ L( diskopatie\n",
      "\n",
      "Punctuation: ,\n",
      "vlhké, bez povlaků\n",
      "TK, p\n",
      "mamy, axily, nadklíčky klinicky bez patologie\n",
      "bez potíží, váha za poslední rok stac, bez dyspepsií, dušnosti, bolesti O\n",
      "vpravo mamma dif bez tu léze, axila O na kůži dif bez patol.eflor\n",
      "bránice je hladká, v obvyklé výši\n",
      "břicho,měkké,prohmanté,nebol\n",
      "občasné bolesti kolem L lopatky, propagace dopředu\n",
      "RTG hrudníku, PA projekce\n",
      "dif bez tu léze, aixla O, nadklíček o, PHK bez edému vlevo mamma dif bez tu léze,axila o\n",
      "\n",
      "Punctuation: -\n",
      "CORE - CUT biopsie z levé axilly pod UZ kontrolou\n",
      "adjuvantní radioterapii na hrudní stěnu vpravo + axilu vpravo ( I-IV.etáž\n",
      "core-cut\n",
      "core-cut biopsii ZHK pravého prsu\n",
      "NACT - AC\n",
      "CKD 2-3\n",
      "vlevo-O,axila i nadkl.O\n",
      "bolest - 0 - žádná, dušnost - 0 - bez obtíží, zvracení - 0 - nezvrací\n",
      "vpravio v ZDQ hmatná resistence cca 2-3 cm\n",
      "stolice častější a řidší- max. 2/den\n",
      "\n",
      "Punctuation: .\n",
      "sinus ry., f 95/min., bez akut. isch. změn\n",
      "nejsou evid. patol. uzliny\n",
      "oper. hemeroidů\n",
      "antiemet. terapie Akynzeo\n",
      "mastectomia simplex mammae l. dx s dolní etáži pravé axily\n",
      "radioterapie na oblast mamy l.sin. a a uzlin l.sin\n",
      "SNB axillae l. sin. No I\n",
      "adjuv., CHT\n",
      "2.čtení\n",
      "homans bilat. negat\n",
      "\n",
      "Punctuation: /\n",
      "premedikace 1/2 tbl Dithiaden + Lexaurin\n",
      "TK 125/80\n",
      "taxol/CBDCA\n",
      "PET/CT\n",
      "stolice častější a řidší- max. 2/den\n",
      "80/ MIN\n",
      "calcium/vit D\n",
      "sinus ry., f 95/min., bez akut. isch. změn\n",
      "ADM/CFA [AC\n",
      "alozexca/D\n",
      "\n",
      "Punctuation: :\n",
      "DKK: volně pohybl\n",
      "alergie: Ketazon (urtika\n",
      "operace: 0\n",
      "alergie: O\n",
      "axila i nadkl:O\n",
      "hormonální léčba: HA + HRT\n",
      "gynekolog. operace: O\n",
      "gynekologické operace: neguje\n",
      "OPERACE: Mastectomia part. l. sin\n",
      "parestezie: 0\n",
      "\n",
      "Punctuation: ;\n",
      "HR;BR\n",
      "\n",
      "Punctuation: [\n",
      "ADM/CFA [AC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temp = data.sample(200, random_state=10)\n",
    "for p in sorted(list(punc_in_data)):\n",
    "    print(f\"Punctuation: {p}\")\n",
    "    data[data[\"text\"].apply(lambda x: p in x)].sample(frac=1, random_state=10).head(10)[\"text\"].apply(lambda x: print(x))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18bb7c-ed7e-4242-bdcc-b68c1a3994a0",
   "metadata": {},
   "source": [
    "We can see, that most of the punctuation have no specific meaning, so we can substitute them with space (most of them stands there instead of space).\n",
    "\n",
    "On the other hand colon has specific meaning, its meaning is specific some category and the rest from the text is about it.\n",
    "\n",
    "And dot have specific meaning, which specify that the word is only shortcut or dash which is part of some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e52435d1-6136-4e27-af6d-48c63d20d6c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_improved_punctuation = data.copy()\n",
    "data_improved_punctuation[\"original_text\"] = data[\"text\"]\n",
    "data_improved_punctuation[\"text\"] = data_improved_punctuation[\"text\"].apply(\n",
    "    lambda text: \"\".join([l if l not in punctuation or l in [\".\"] else \" \" for l in text]))\n",
    "data_improved_punctuation[\"text\"] = data_improved_punctuation[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93fec8-ba00-4618-8f0e-3198007b4c48",
   "metadata": {},
   "source": [
    "If we inspect the longer matches, we can see, that many times we've got there nonsense combination (like word with conjunction behind it). For this reason I am going to modify the algorithm, where it will preserve even the shorter matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b13bd81-6662-4332-9afc-9777bd93df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'beze změny': 'tropismus'}, {'sekund a': 'syndromy spánkové apnoe', 'lymfedém a': 'syndrom žlutých nehtů', 'pod hrudní': 'bederní obratle', 'pod a': 'parotis', 'hrudní a': 'bránice', 'stěnou a': 'sagitální abdominální rozměr'}, {'změny s': 'incontinentia pigmenti', 's mnohočetnými': 'vrozené srdeční vady'}, {'vše v': 'naučená bezmocnost'}, {'v kloubech': 'synoviální cysta', 'v a': 'parciální tromboplastinový čas', 'a kloubech': 'juvenilní artritida', 'a kyčelních': 'artróza kyčelních kloubů'}]\n",
      "[{'hrudní a': 'Thoracoabdominal aortic aneurysm'}, {'jizva v': \"Vaccination site scar',\"}, {'Baker. cysta': \"Popliteal Cyst',\"}, {'změny s': 'Mood alterations with depressive symptoms\\',\",'}, {'TEN 0': \"WHODAS 2.0 12-item Version Proxy-administered - Concentrating for Ten Minutes',\"}]\n"
     ]
    }
   ],
   "source": [
    "temp = test_new_access[\"medvik_explanation\"].apply(lambda x: {k: x[k][1] for k in x if len(k.split(\" \")) >= 2 if x[k] is not None})\n",
    "print(list(temp[temp != {}].head(5)))\n",
    "temp = test_new_access[\"mash_explanation\"].apply(lambda x: {k: x[k][1] for k in x if len(k.split(\" \")) >= 2 if x[k] is not None})\n",
    "print(list(temp[temp != {}].head(5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
