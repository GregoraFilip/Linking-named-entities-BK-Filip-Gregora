{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec09843",
   "metadata": {},
   "source": [
    "# Linking named entities\n",
    "by Filip Gregora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c163ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from string import punctuation, ascii_letters\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import xml.etree.ElementTree as elt\n",
    "from openai import OpenAI\n",
    "import regex\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62645ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>Novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>Označena SLU v levé axile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>Cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      Novalgin\n",
       "3     symptom    Označena SLU v levé axile.\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             Založení TE l.sin\n",
       "7   procedura                   Cytostatika\n",
       "8  NE symptom         přiměřené echogenity,\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/NER_entities.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6678d27",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "At the beginning we want to explore data.\n",
    "\n",
    "- We can see that somewhere there is big letter at the beginning (but be carefull when whole first word is written in upper case)\n",
    "- Somewhere at the end is interpuncion\n",
    "- There are lots of duplicates\n",
    "- the length of text is variable and the longest has 20 words (this can be problem in the future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f247a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2588"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881afc66-b8fb-4b93-ad5e-904f26495ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b494df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6034 -> 2803 : 3231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>symptom</td>\n",
       "      <td>označena SLU v levé axile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st.p. totální ME + SNB vlevo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medikace</td>\n",
       "      <td>NOVALGIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>procedura</td>\n",
       "      <td>založení TE l.sin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>procedura</td>\n",
       "      <td>cytostatika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>přiměřené echogenity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>nezvětšena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                          text\n",
       "0     symptom        jemný fibrózní proužek\n",
       "1   procedura             neoadjuvantní CHT\n",
       "2    medikace                      novalgin\n",
       "3     symptom     označena SLU v levé axile\n",
       "4   procedura  st.p. totální ME + SNB vlevo\n",
       "5    medikace                      NOVALGIN\n",
       "6   procedura             založení TE l.sin\n",
       "7   procedura                   cytostatika\n",
       "8  NE symptom          přiměřené echogenity\n",
       "9  NE symptom                    nezvětšena"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(string):\n",
    "    string = string.strip(\" \" + \"\".join(punctuation))\n",
    "    # Remove first upper letter if not all letters are upper\n",
    "    if len(string) >= 2:\n",
    "        string = string[0].lower() + string[1:] if string[1].islower() else string\n",
    "    # Replace multiple whitespaces with one\n",
    "    return \" \".join(string.split())\n",
    "\n",
    "def clean_table(db):\n",
    "    db_copy = db.copy()\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].apply(clean)\n",
    "    db_copy[\"text\"] = db_copy[\"text\"].drop_duplicates()\n",
    "    return db_copy.dropna()\n",
    "\n",
    "former_len = len(data)\n",
    "data = clean_table(data)\n",
    "print(former_len, \"->\", len(data), \":\", former_len - len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bc06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1 | 2: 3 | 3: 7 | 4: 15 | 5: 31 | 6: 63 | 7: 127 | 8: 255 | 9: 511 | 10: 1023 | 11: 2047 | 12: 4095 | 13: 8191 | 14: 16383 | 15: 32767 | 16: 65535 | 17: 131071 | 18: 262143 | 19: 524287 | 20: 1048575 | "
     ]
    },
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comb_sum(j):\n",
    "    sum = 0\n",
    "    for i in range(j, 0, -1):\n",
    "        sum += math.comb(j,i)\n",
    "    return sum\n",
    "\n",
    "for i in range(1, 21):\n",
    "    print(i, comb_sum(i), sep = \": \", end = \" | \")\n",
    "    \n",
    "lenght_data = data[\"text\"].apply(lambda x: len(x.split(\" \")))\n",
    "len(lenght_data[lenght_data >= 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc45a11",
   "metadata": {},
   "source": [
    "## Linking\n",
    "Our approach to linking entities is:\n",
    "- Link words to some medicinal database.\n",
    "- Let some pretrained language model to choose the best from them.\n",
    "\n",
    "So I can compare I decided to use two approaches for linking. The first one is to use international mesh and access it via web API of NIH (National Institute of Health).\n",
    "\n",
    "The second is to use czech mesh. I accessed it from predownloaded file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb7a63-1b02-4215-9063-9a24cfddbe18",
   "metadata": {},
   "source": [
    "\n",
    "### Linking to international MESH through NIH\n",
    "Mash is international medical databaze: https://uts.nlm.nih.gov/uts/.\n",
    "\n",
    "I tried search all combinations of words from text in databaze. The longer combinations have higher priority. \n",
    "\n",
    "There is one big problem, the complexity grows exponentially with the lenght of the words (in the worst case for lenght of 20 we have to try around 10^6 combinations). My solution for this problem is go from bottom up, start with lenght 1 and continue only with combinations which success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cd1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not search in databaze if it number or it is too short (shorter than 2)\n",
    "def filter_short(string):\n",
    "    return len(string) < 2 or string.isdigit()\n",
    "    \n",
    "    \n",
    "def print_linking_stats(data_list):\n",
    "    empty = len(data_list[data_list.apply(lambda x: len(x) == 0)])\n",
    "    print(f\"Number of empty: {empty} ({empty / len(data_list) * 100} %)\")\n",
    "\n",
    "    number_of_matches = data_list.apply(lambda x: len(x))\n",
    "    print(f\"Mean from number of matches: {number_of_matches.mean()}\")\n",
    "    print(f\"Median from number of matches: {number_of_matches.median()}\")\n",
    "    print(f\"Maximal of matches: {number_of_matches.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d79706-d8f6-4d8c-9268-4936a0cdaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From string to list which contains tuples\n",
    "def from_string_to_list(string):\n",
    "    result = []\n",
    "    for j in string.strip(\"[]()\").split(\"), (\"):\n",
    "        if len(j) == 0:\n",
    "            continue\n",
    "        result.append(tuple([s.strip(\"'\\\" \\\\\") for s in j.split(\"', \")]))\n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "#From string to tuple\n",
    "def from_string_to_tuple(string):\n",
    "    if string == \"N/A\":\n",
    "        return\n",
    "    string = string.strip(\"\\\\\\\" '\")\n",
    "    stripped_string = string[0].strip(\"(\") + string[1:-1] + string[-1].strip(\")\")\n",
    "    \n",
    "    result = [i.strip(\"\\\\\\\"'\") for i in stripped_string.split(\", \")]\n",
    "    return (result[0], result[1], \", \".join(result[2:]))\n",
    "\n",
    "\n",
    "#From string to dictionary\n",
    "def from_string_to_dict(string):\n",
    "    result = {}\n",
    "    for j in string.strip(\"{} \").split(\"], \"):\n",
    "        if j == \"\":\n",
    "            continue\n",
    "        i = list(j.split(\": [\"))\n",
    "        assert len(i) == 2\n",
    "        result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_list(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#From string to dictionary which contains tuples\n",
    "def from_string_to_dict_to_tuple(string):\n",
    "    result = {}\n",
    "    for j in regex.split(\"(\\)| None), ('|\\\")\", string.strip(\"{} \")):\n",
    "        if j in [\"\", ')', ' None', \"'\", '\"']:\n",
    "            continue\n",
    "        i = list(j.split(\": (\"))\n",
    "        if len(i) == 1:\n",
    "            i[0] = i[0].split(\": None\")[0].strip(\": \")\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = None\n",
    "        else:\n",
    "            result[i[0].strip(\"\\\"\\' \\\\\")] = from_string_to_tuple(i[1])\n",
    "\n",
    "    return result\n",
    "\n",
    "#From string to dictionary with ints\n",
    "from_string_to_int_dict = (lambda x: {elem.split(\"': \")[0].strip(\"' \\\"\") : int(elem.split(\"': \")[1])\n",
    "                                      for elem in x.strip(\"{}\\\"' \").split(\", '\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b15b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../APIkeys/NIH\", \"r\") as f:\n",
    "    NIH_api = f.read()\n",
    "\n",
    "def mash_slow_search(string):\n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    for j in range(len(splitted_input), 0, -1):\n",
    "        for string in combinations(splitted_input, j): \n",
    "            if filter_short(\" \".join(string)):\n",
    "                continue\n",
    "                \n",
    "            path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "            query = {\n",
    "                     'string': \" \".join(string),\n",
    "                     'apiKey':NIH_api,\n",
    "            }\n",
    "            res = requests.get(path, params=query)\n",
    "\n",
    "            if res.status_code <= 200:\n",
    "                data = json.loads(res.text)\n",
    "                for j in data[\"result\"][\"results\"]:\n",
    "                    result.append((j[\"ui\"], j[\"name\"]))\n",
    "            else:\n",
    "                print(res.status_code, res.text)\n",
    "        \n",
    "        if len(result) != 0:\n",
    "            break\n",
    "                        \n",
    "    return result\n",
    "        \n",
    "    \n",
    "def search_from_bottom(string, func, output_state = False):\n",
    "    if (output_state):\n",
    "        global count\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    splitted_input = (string.split(\" \"))\n",
    "    result = []\n",
    "    last_result = []\n",
    "    lenght = len(splitted_input)\n",
    "    \n",
    "    for j in range(1, lenght + 1):\n",
    "        splitted_dict={}\n",
    "        for elem in splitted_input:\n",
    "            splitted_dict[j] = False\n",
    "                    \n",
    "        for words in combinations(splitted_input, j):\n",
    "            data = func(\" \".join(words))\n",
    "            if len(data) != 0:\n",
    "                for j in words:\n",
    "                    splitted_dict[j] = True\n",
    "                if filter_short(\" \".join(words)):\n",
    "                    continue\n",
    "                result.append(data)\n",
    "\n",
    "        splitted_input = [j for j, i in splitted_dict.items() if i]\n",
    "        if len(splitted_input) == 0:\n",
    "            break\n",
    "        else:\n",
    "            last_result, result = result, []\n",
    "        \n",
    "    temp = []\n",
    "    for j in last_result:\n",
    "        temp += list(enumerate(j))\n",
    "    return [j for (i, j) in sorted(temp)]\n",
    "    \n",
    "    \n",
    "def mash_search(string):\n",
    "    path = 'https://uts-ws.nlm.nih.gov/rest/search/current'\n",
    "    query = {\n",
    "             'string': string,\n",
    "             'apiKey':NIH_api,\n",
    "    }\n",
    "    res = requests.get(path, params=query)\n",
    "\n",
    "    if res.status_code <= 200:\n",
    "        data = json.loads(res.text)          \n",
    "        return [(j[\"ui\"], j[\"name\"]) for j in data[\"result\"][\"results\"]]\n",
    "    else:\n",
    "        print(res.status_code, res.text)\n",
    "        return []\n",
    "    \n",
    "\n",
    "def seach_table(db, func):\n",
    "    db = db.copy()\n",
    "    db[\"search\"] = db[\"text\"].apply(func)\n",
    "    return db \n",
    "    \n",
    "\n",
    "def mash_search_table(db):\n",
    "    return seach_table(db, lambda x: search_from_bottom(x, mash_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5939f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../saved_search/data_mash.csv\"):\n",
    "    mash_linked_data = pd.read_csv(\"../saved_search/data_mash.csv\")\n",
    "    mash_linked_data.index = mash_linked_data[\"Unnamed: 0\"]\n",
    "    mash_linked_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    mash_linked_data[\"search\"] = mash_linked_data[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    mash_linked_data = mash_search_table(data)\n",
    "    mash_linked_data.to_csv(\"../saved_search/data_mash.csv\")\n",
    "    \n",
    "print_linking_stats(mash_linked_data[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ef10f4",
   "metadata": {},
   "source": [
    "#### Not assigned\n",
    "If we look at the random sample of 10 texts, which are not assigned, then we can see that in five of them there is typographical mistake (*\"nejsou zn.plicní hpertenze\"* = *\"nejsou zn. plicní hypertenze\"*, *\"kumulce a nehomogenity\"* = *\"kumulace a nehomogenita\"*, *\"ceriucal\"* = *\"cerucal\"*, *\"paitace\"* = *\"palpitace\"*, *\"mamily klidné\"* = ?). Others five are correct medical term, but in some non-typical grammatical form.\n",
    "\n",
    "If we try to improve them we get 50 % improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a153e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # empty_sample = mash_linked_data[mash_linked_data[\"search\"].apply(lambda x: len(x) == 0)].sample(10, random_state=42)\n",
    "\n",
    "# # Because of my mistake (I had worser clean_table), the code above generate different sample than I have worked with.\n",
    "# # So I have to create the sample by hand:\n",
    "# empty_sample = mash_linked_data.loc[[878, 91, 5240, 3728, 1125, 2479, 4981, 1134, 5089, 1129]]\n",
    "\n",
    "# empty_sample[\"text\"][878] = \"nejsou zn. plicní hypertenze\"\n",
    "# empty_sample[\"text\"][91] = \"hormostenické\"\n",
    "# empty_sample[\"text\"][5240] = \"kumulace a nehomogenita\"\n",
    "# empty_sample[\"text\"][3728] = \"biopsie\"\n",
    "# empty_sample[\"text\"][1125] = \"chemobioterapie\"\n",
    "# empty_sample[\"text\"][2479] = \"dysmorfické\"\n",
    "# empty_sample[\"text\"][4981] = \"anikterické\"\n",
    "# empty_sample[\"text\"][1134] = \"cerucal\"\n",
    "# empty_sample[\"text\"][5089] = \"palpitace\"\n",
    "# empty_sample[\"text\"][1129] = \"mamily klidné\"\n",
    "\n",
    "# empty_sample = mash_search_table(empty_sample)\n",
    "# empty_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a45dc4",
   "metadata": {},
   "source": [
    "There is one mistake which we can correct automaticly and it is not having space after punctuation mark. We can see that if we have space after punctuation then it find something, else it didn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9881b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(search_from_bottom(\"zn. plicní\", mash_search)))\n",
    "# print(len(search_from_bottom(\"zn.plicní\", mash_search)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067a1248",
   "metadata": {},
   "source": [
    "We can see that there is around 150 examples of this mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede5ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            return False\n",
    " \n",
    "    return True\n",
    "\n",
    "def insert_space_after_punc(string):\n",
    "    punctuation = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"+\"]\n",
    "    for i in range(len(string) - 1):\n",
    "        if string[i] in punctuation and string[i+1] != \" \" and string[i+1] not in punctuation:\n",
    "            string = string[:i+1] + \" \" + string[i+1:]\n",
    " \n",
    "    return string\n",
    "\n",
    "inserted_space_data = data.copy()\n",
    "inserted_space_data[\"text\"] = inserted_space_data[\"text\"].apply(insert_space_after_punc)\n",
    "no_space = data[~data[\"text\"].apply(is_space_after_punc)]\n",
    "len(no_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2ba076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 298 (10.631466286122013 %)\n",
      "Mean from number of matches: 21.931858722797003\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../saved_search/data_mash_inserted_space.csv\"):\n",
    "    inserted_space_mash_linked_data = pd.read_csv(\"../saved_search/data_mash_inserted_space.csv\")\n",
    "    inserted_space_mash_linked_data.index = inserted_space_mash_linked_data[\"Unnamed: 0\"]\n",
    "    inserted_space_mash_linked_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    inserted_space_mash_linked_data[\"search\"] = inserted_space_mash_linked_data[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    inserted_space_mash_linked_data = mash_linked_data.copy()\n",
    "    no_space[\"text\"] = no_space[\"text\"].apply(insert_space_after_punc)\n",
    "    for i in no_space.index:\n",
    "        inserted_space_mash_linked_data[\"search\"][i] = search_from_bottom(no_space[\"text\"][i], mash_search)\n",
    "        inserted_space_mash_linked_data[\"text\"][i] = no_space[\"text\"][i]\n",
    "    inserted_space_mash_linked_data.to_csv(\"../saved_search/data_mash_inserted_space.csv\")    \n",
    "        \n",
    "print_linking_stats(mash_linked_data[\"search\"])\n",
    "print()\n",
    "print_linking_stats(inserted_space_mash_linked_data[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25133cb",
   "metadata": {},
   "source": [
    "Thanks to this upgrade we improved search by finding 40 new matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03172cc",
   "metadata": {},
   "source": [
    "### Linking to CZ Mash through Medvik \n",
    "\n",
    "Now we try to link through czech mash, I have downloaded it from NLK (národní lékařská knihovna): https://nlk.cz/pro-knihovny/data/#mesh-cz\n",
    "\n",
    "I called this linking as Medvik, because there is web service called Medvik: https://www.medvik.cz/bmc/subject.do, where you can search in czech mash.\n",
    "\n",
    "I used already improved methods from Mash_search. First I experimenced with search, which tests if contains gived text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d500763",
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_mshcz = elt.parse('../databaze/MeSH2023_Marc21_Alma.xml').getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbaf7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patternize(string):\n",
    "    result = []\n",
    "    for i in string:\n",
    "        if i in '<([{\\\\^-=$!|]})?*+.>]':\n",
    "            result.append(\"\\\\\" + i)\n",
    "        else:\n",
    "            result.append(i)\n",
    "    return \"\".join(result)\n",
    "\n",
    "\n",
    "def medvik_search(string, test):\n",
    "    result = []\n",
    "    for child in offline_mshcz:\n",
    "        for subchild in child.iter(\"{http://www.loc.gov/MARC21/slim}subfield\"):\n",
    "            if subchild.text and test(string, subchild.text):\n",
    "                try:\n",
    "                    code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "                    name = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"150\" ][0][0].text\n",
    "                    result.append((code, name))\n",
    "                    break\n",
    "                except IndexError:\n",
    "                    break                \n",
    "    return result\n",
    "\n",
    "\n",
    "def medvik_exact_search(string):              \n",
    "    return medvik_search(string, lambda x, y: x.lower() == y.lower())\n",
    "\n",
    "\n",
    "def medvik_words_search(string):      \n",
    "    return medvik_search(string, lambda x, y: (\" \" + x.lower() + \" \") in y.lower())\n",
    "\n",
    "\n",
    "def medvik_match_search(string):\n",
    "    return medvik_search(string, lambda x, y: x.lower() in y.lower())\n",
    "\n",
    "\n",
    "def medvik_combined_search(string):\n",
    "    result = medvik_exact_search(string)\n",
    "    if len(result) == 0:\n",
    "        result = medvik_words_search(string)\n",
    "    if len(result) == 0:\n",
    "        result = medvik_match_search(string)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def medvik_exact_search_table(db):\n",
    "    return seach_table(db, lambda x: search_from_bottom(x, medvik_exact_search, output_state=True))\n",
    "\n",
    "\n",
    "def medvik_words_search_table(db):\n",
    "    return seach_table(db, lambda x: search_from_bottom(x, medvik_words_search, output_state=True))\n",
    "    \n",
    "\n",
    "def medvik_match_search_table(db):\n",
    "    return seach_table(db, lambda x: search_from_bottom(x, medvik_match_search, output_state=True))\n",
    "\n",
    "\n",
    "def medvik_combined_search_table(db):\n",
    "    return seach_table(db, lambda x: search_from_bottom(x, medvik_combined_search, output_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56ec8297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../saved_search/data_medvik_contains.csv\"):\n",
    "    medvik_match_search_data = pd.read_csv(\"../saved_search/data_medvik_contains.csv\")\n",
    "    medvik_match_search_data.index = medvik_match_search_data[\"Unnamed: 0\"]\n",
    "    medvik_match_search_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    medvik_match_search_data[\"search\"] = medvik_match_search_data[\"search\"].apply(from_string_to_list)\n",
    "    \n",
    "else:\n",
    "    count = 0\n",
    "    medvik_match_search_data = medvik_match_search_table(inserted_space_data)\n",
    "    medvik_match_search_data.to_csv(\"../saved_search/data_medvik_contains.csv\")\n",
    "    \n",
    "print_linking_stats(inserted_space_mash_linked_data[\"search\"])\n",
    "print()\n",
    "print_linking_stats(medvik_match_search_data[\"search\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6567ee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1904, 1720, 0, 27715, 1722, 94, 9, 10724, 0, 112]\n",
      "number of searches longer than 100 matches in medvik_match_search_data: 1017\n"
     ]
    }
   ],
   "source": [
    "print([i for i in medvik_match_search_data[\"search\"].apply(lambda x: len(x)).sample(10, random_state=42)])\n",
    "\n",
    "temp = medvik_match_search_data[\"search\"].apply(lambda x: len(x))\n",
    "print(f\"number of searches longer than 100 matches in medvik_match_search_data: {len(temp[temp > 100])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2418733",
   "metadata": {},
   "source": [
    "We can see, that for some examples this is working well. But for some we have really lots of samples whose lenght grows exponentially.\n",
    "\n",
    "For this reasons it might be better to use some different match method instead:\n",
    "- First method is contain search (I used it before) - test if contains given text\n",
    "- Next method is word search - test if contains given text as word (there are spaces around)\n",
    "- Next method is exact search - test if contains exactly given text\n",
    "- The last method is combined search - first text exact, then word, then contains (if some success then end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53dd6c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 2265.2\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 27715\n",
      "\n",
      "Words match\n",
      "Number of empty: 6 (30.0 %)\n",
      "Mean from number of matches: 194.0\n",
      "Median from number of matches: 5.5\n",
      "Maximal of matches: 1918\n",
      "\n",
      "Exact match\n",
      "Number of empty: 11 (55.00000000000001 %)\n",
      "Mean from number of matches: 3.05\n",
      "Median from number of matches: 0.0\n",
      "Maximal of matches: 22\n",
      "\n",
      "Combined match\n",
      "Number of empty: 3 (15.0 %)\n",
      "Mean from number of matches: 261.95\n",
      "Median from number of matches: 6.5\n",
      "Maximal of matches: 1904\n"
     ]
    }
   ],
   "source": [
    "test_data = inserted_space_data.sample(20, random_state=42)\n",
    "\n",
    "if os.path.isfile(\"../saved_search/test_medvik.csv\"):\n",
    "    test_data = pd.read_csv(\"../saved_search/test_medvik.csv\")\n",
    "    test_data[\"search_match\"] = test_data[\"search_match\"].apply(from_string_to_list)\n",
    "    test_data[\"search_exact\"] = test_data[\"search_exact\"].apply(from_string_to_list)\n",
    "    test_data[\"search_words\"] = test_data[\"search_words\"].apply(from_string_to_list)\n",
    "    test_data[\"search_combined\"] = test_data[\"search_combined\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    test_data[\"search_match\"] = medvik_match_search_table(test_data)[\"search\"]\n",
    "    test_data[\"search_exact\"] = medvik_exact_search_table(test_data)[\"search\"]\n",
    "    test_data[\"search_words\"] = medvik_words_search_table(test_data)[\"search\"]\n",
    "    test_data[\"search_combined\"] = medvik_combined_search_table(test_data)[\"search\"]\n",
    "    test_data.to_csv(\"../saved_search/test_medvik.csv\")\n",
    "    \n",
    "print(\"Contains match\")\n",
    "print_linking_stats(test_data[\"search_match\"])\n",
    "print(\"\\nWords match\")\n",
    "print_linking_stats(test_data[\"search_words\"])\n",
    "print(\"\\nExact match\")\n",
    "print_linking_stats(test_data[\"search_exact\"])\n",
    "print(\"\\nCombined match\")\n",
    "print_linking_stats(test_data[\"search_combined\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9b5a0",
   "metadata": {},
   "source": [
    "We can see that using exact match we get rid of the long matches but it have quite low success rate. Using words match is something in the middle (not good in both ways).\n",
    "\n",
    "As last option we used combined match (first try exact, if don't success then words, then only match). This seems as the best methods (this doesn't create too large lists and has the same number of empty matches as contains match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05709eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../saved_search/data_medvik_combined.csv\"):\n",
    "    medvik_combined_search_data = pd.read_csv(\"../saved_search/data_medvik_combined.csv\")\n",
    "    medvik_combined_search_data.index = medvik_combined_search_data[\"Unnamed: 0\"]\n",
    "    medvik_combined_search_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    medvik_combined_search_data[\"search\"] = medvik_combined_search_data[\"search\"].apply(from_string_to_list)\n",
    "else:\n",
    "    count = 0\n",
    "    medvik_combined_search_data = medvik_combined_search_table(inserted_space_data)\n",
    "    medvik_combined_search_data.to_csv(\"../saved_search/data_medvik_combined.csv\")\n",
    "       \n",
    "print_linking_stats(medvik_combined_search_data[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4d23d",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "It is possible to get duplicates in list of matches, when getting the same match from two different words from text (or combinations of the same lenght) \n",
    "\n",
    "In mash search there are few duplicates, but in medvik search it can be serious problem - we can see, that maximum of matches in contains search is reduced nearly by 15 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25363344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inserted_space_mash_linked_data[~inserted_space_mash_linked_data[\"search\"].apply(lambda x: len(set(x)) == len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2e0d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.350338922582946\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1670.0117731002497\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 43684\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 488.3999286478773\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n",
      "\n",
      "\n",
      "After removing duplicates:\n",
      "Mash search\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.33927934356047\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "\n",
      "Medvik contains search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 1625.7213699607564\n",
      "Median from number of matches: 28.0\n",
      "Maximal of matches: 29327\n",
      "\n",
      "Medvik combined search\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 481.9782376025687\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n"
     ]
    }
   ],
   "source": [
    "def remove_dup_preserve_order(l):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in l if not (x in seen or seen_add(x))]\n",
    "\n",
    "\n",
    "print(\"Before removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_linking_stats(inserted_space_mash_linked_data[\"search\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_linking_stats(medvik_match_search_data[\"search\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_linking_stats(medvik_combined_search_data[\"search\"])\n",
    "\n",
    "inserted_space_mash_linked_data[\"search\"] = inserted_space_mash_linked_data[\"search\"].apply(remove_dup_preserve_order)\n",
    "medvik_match_search_data[\"search\"] = medvik_match_search_data[\"search\"].apply(remove_dup_preserve_order)\n",
    "medvik_combined_search_data[\"search\"] = medvik_combined_search_data[\"search\"].apply(remove_dup_preserve_order)\n",
    "\n",
    "print(\"\\n\\nAfter removing duplicates:\")\n",
    "print(\"Mash search\")\n",
    "print_linking_stats(inserted_space_mash_linked_data[\"search\"])\n",
    "print(\"\\nMedvik contains search\")\n",
    "print_linking_stats(medvik_match_search_data[\"search\"])\n",
    "print(\"\\nMedvik combined search\")\n",
    "print_linking_stats(medvik_combined_search_data[\"search\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2177a4b",
   "metadata": {},
   "source": [
    "## Choosing best match with Chat GPT\n",
    "The idea behind our model is first link term to database and then choose the best one by some pretrained language model.\n",
    "\n",
    "I use GPT-3.5, because it is free to access with limitations (There are some limits of access per day. And there is limited number of access per account. Then we have to pay.), it is fast and it is well known.\n",
    "\n",
    "The message to GPT is in this format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b5917d",
   "metadata": {},
   "source": [
    "Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \"[MEDICAL TERM]\":\n",
    "\n",
    "    1. [DESCRIPTION_N.1] (pojem: [TERM_N.1])\n",
    "    2. [DESCRIPTION_N.2] (pojem: [TERM_N.2])\n",
    "    ...\n",
    "    \n",
    "Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a818507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medvik_find_by_code(string):\n",
    "    if len(string) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    for child in offline_mshcz:\n",
    "        try:\n",
    "            code = [i for i in child.findall(\"{http://www.loc.gov/MARC21/slim}controlfield\") if i.attrib[\"tag\"] == \"001\" ][0].text\n",
    "            if code == string:\n",
    "                d = [i.iter(\"{http://www.loc.gov/MARC21/slim}subfield\") for i in child.findall(\"{http://www.loc.gov/MARC21/slim}datafield\") if i.attrib[\"tag\"] == \"680\"][0]\n",
    "                return next(d).text\n",
    "        except IndexError:\n",
    "            continue      \n",
    "            \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def mash_find_by_code(string):\n",
    "    path = f'https://uts-ws.nlm.nih.gov/rest/content/current/CUI/{string}'\n",
    "    query = {\n",
    "             'apiKey':NIH_api,\n",
    "    }\n",
    "    res = requests.get(path, params=query)\n",
    "    \n",
    "    if res.status_code <= 200:\n",
    "        try:\n",
    "            data = json.loads(res.text)\n",
    "            definition = data[\"result\"][\"definitions\"]\n",
    "\n",
    "            if \"https://uts-ws.nlm.nih.gov/\" in definition:\n",
    "                path = definition\n",
    "                res = requests.get(path,params=query)\n",
    "                try:\n",
    "                    return [i[\"value\"] for i in json.loads(res.text)[\"result\"] if i[\"rootSource\"] == \"MSHCZE\"][0]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                try:\n",
    "                    return [i[\"value\"] for i in json.loads(res.text)[\"result\"] if i[\"rootSource\"] == \"MSH\"][0]\n",
    "                except IndexError:\n",
    "                    definition = \"NONE\"\n",
    "        except Exception:\n",
    "            definition = \"NONE\"\n",
    "            print(string, res.text)\n",
    "        \n",
    "        if definition == \"NONE\":\n",
    "            return data[\"result\"][\"name\"]\n",
    "        \n",
    "        return definition\n",
    "    else:\n",
    "        print(string)\n",
    "        print(res.status_code, res.text)\n",
    "        \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17707115",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../APIkeys/NIH\", \"r\") as f:\n",
    "    NIH_api = f.read()\n",
    "\n",
    "def send_to_GPT(message):\n",
    "    if message == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    with open(\"../APIkeys/chatGTP\", \"r\") as f:\n",
    "        chatgpt_api = f.read()\n",
    "\n",
    "    client = OpenAI(api_key=chatgpt_api)\n",
    "    return client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-16k\",\n",
    "                messages=[{\"role\": \"user\", \"content\": message}],\n",
    "                stream=False)\n",
    "\n",
    "\n",
    "def message_for_GPT(string, li, find, context=None):\n",
    "    if len(li) == 0:\n",
    "        return \"\"\n",
    "            \n",
    "    if context is None:\n",
    "        result = [f\"Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \\\"{string}\\\":\\n\"]\n",
    "    else:\n",
    "        result = [f\"Který z uvedených lékařských pojmů s jeho popisem nejlépe odpovídá pojmu: \\\"{string}\\\" v kontextu:  \\\"{context}\\\":\\n\"]\n",
    "        \n",
    "    j = 1\n",
    "    for i in li:\n",
    "        result.append(f\"{j}. {find(i[0])} (pojem: {i[1]})\\n\")\n",
    "        j += 1\n",
    "        \n",
    "    result.append(\"Jako odpověď mi pošli pouze číslo odpovědi. Pokud to nebude žádná z možností, pak odpověz NONE. Pokud to není lékařský pojem odpověz taky NONE.\")\n",
    "    \n",
    "    return \"\".join(result)\n",
    "    \n",
    "def find_int(string):\n",
    "    result = []\n",
    "    for i in string:\n",
    "        if i.isdigit():\n",
    "            result.append(i)\n",
    "\n",
    "    return int(\"\".join(result))\n",
    "\n",
    "\n",
    "def from_GPT(result, li, find):\n",
    "    try:\n",
    "        i = find_int(result.choices[0].message.content) - 1\n",
    "        return (li[i][0], li[i][1], find(li[i][0]))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650e610",
   "metadata": {},
   "source": [
    "Because ChatGPT has problem with long messages (and sometimes we get really long results with medvik_combined), we have to restrict these messages and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6876643c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>mash_search</th>\n",
       "      <th>medvik_search_combined</th>\n",
       "      <th>mash_explanation</th>\n",
       "      <th>medvik_explanation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>NE symptom</td>\n",
       "      <td>KI100</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>procedura</td>\n",
       "      <td>st. p. tru-cut biopsii</td>\n",
       "      <td>[(C1170898, Companion P/ST 1000ML), (C4015802,...</td>\n",
       "      <td>[(D000039, peritonzilární absces), (D000081182...</td>\n",
       "      <td>(C5700874, Percutaneous pulmonary artery revas...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>osobní anamnéza</td>\n",
       "      <td>konizace čípku</td>\n",
       "      <td>[(C0195324, Conization)]</td>\n",
       "      <td>[(D002583, nádory děložního čípku), (D019092, ...</td>\n",
       "      <td>(C0195324, Conization, Kruhovité kuželovité vy...</td>\n",
       "      <td>(D019092, konizace děložního čípku, Kruhovité ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>procedura</td>\n",
       "      <td>operace: ITP</td>\n",
       "      <td>[(C0398650, Immune thrombocytopenic purpura), ...</td>\n",
       "      <td>[(D007293, inosintrifosfát)]</td>\n",
       "      <td>(C3842543, Idiopathic thrombocytopenia (ITP), ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>symptom</td>\n",
       "      <td>neostře konturované ložisko 7x5mm</td>\n",
       "      <td>[(C0241148, Cutaneous plaque), (C1533591, Calc...</td>\n",
       "      <td>[(D001253, astrocyty), (D002833, choroiditida)...</td>\n",
       "      <td>(C0235456, Thyroid nodular, Thyroid nodular)</td>\n",
       "      <td>(D002833, choroiditida, Zánět cévnatky, zadní ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      label                               text  \\\n",
       "Unnamed: 0                                                       \n",
       "1633             NE symptom                              KI100   \n",
       "5536              procedura             st. p. tru-cut biopsii   \n",
       "412         osobní anamnéza                     konizace čípku   \n",
       "4517              procedura                       operace: ITP   \n",
       "5757                symptom  neostře konturované ložisko 7x5mm   \n",
       "\n",
       "                                                  mash_search  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                       []   \n",
       "5536        [(C1170898, Companion P/ST 1000ML), (C4015802,...   \n",
       "412                                  [(C0195324, Conization)]   \n",
       "4517        [(C0398650, Immune thrombocytopenic purpura), ...   \n",
       "5757        [(C0241148, Cutaneous plaque), (C1533591, Calc...   \n",
       "\n",
       "                                       medvik_search_combined  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                       []   \n",
       "5536        [(D000039, peritonzilární absces), (D000081182...   \n",
       "412         [(D002583, nádory děložního čípku), (D019092, ...   \n",
       "4517                             [(D007293, inosintrifosfát)]   \n",
       "5757        [(D001253, astrocyty), (D002833, choroiditida)...   \n",
       "\n",
       "                                             mash_explanation  \\\n",
       "Unnamed: 0                                                      \n",
       "1633                                                     None   \n",
       "5536        (C5700874, Percutaneous pulmonary artery revas...   \n",
       "412         (C0195324, Conization, Kruhovité kuželovité vy...   \n",
       "4517        (C3842543, Idiopathic thrombocytopenia (ITP), ...   \n",
       "5757             (C0235456, Thyroid nodular, Thyroid nodular)   \n",
       "\n",
       "                                           medvik_explanation  \n",
       "Unnamed: 0                                                     \n",
       "1633                                                     None  \n",
       "5536                                                     None  \n",
       "412         (D019092, konizace děložního čípku, Kruhovité ...  \n",
       "4517                                                     None  \n",
       "5757        (D002833, choroiditida, Zánět cévnatky, zadní ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(\"../saved_search/explanation_sample.csv\"):\n",
    "    explanation = pd.read_csv(\"../saved_search/explanation_sample.csv\")\n",
    "    explanation.index = explanation[\"Unnamed: 0\"]\n",
    "    explanation.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    explanation[\"mash_explanation\"] = explanation[\"mash_explanation\"].fillna(value=\"N/A\").apply(from_string_to_tuple)\n",
    "    explanation[\"medvik_explanation\"] = explanation[\"medvik_explanation\"].fillna(value=\"N/A\").apply(from_string_to_tuple)\n",
    "    explanation[\"mash_search\"] = explanation[\"mash_search\"].apply(from_string_to_list)\n",
    "    explanation[\"medvik_search_combined\"] = explanation[\"medvik_search_combined\"].apply(from_string_to_list)\n",
    "else:\n",
    "    explanation = results.sample(100, random_state=38)\n",
    "    explanation[\"mash_explanation\"] = \"N/A\"\n",
    "    for j in explanation.index:\n",
    "        message = message_chatGTP(explanation[\"text\"][j], explanation[\"mash_search\"][j], mash_find_by_code)\n",
    "        response = send_to_GPT(message)\n",
    "        explanation[\"mash_explanation\"][j] = from_GPT(response, explanation[\"mash_search\"][j], mash_find_by_code)     \n",
    "        \n",
    "#         If the message is too long we cannot send it to chatGPT, so we drop shorter messages.\n",
    "        if len(explanation[\"medvik_search_combined\"][j]) > 50:\n",
    "            continue\n",
    "        message = message_for_GPT(explanation[\"text\"][j], explanation[\"medvik_search_combined\"][j], medvik_find_by_code)\n",
    "        response = send_to_GPT(message)\n",
    "        explanation[\"medvik_explanation\"][j] = from_GPT(response, explanation[\"medvik_search_combined\"][j], medvik_find_by_code)\n",
    "    explanation.to_csv(\"../saved_search/explanation_sample.csv\")\n",
    "\n",
    "explanation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d125c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explanation[explanation[\"medvik_search_combined\"].apply(lambda x: len(x) > 50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018cda",
   "metadata": {},
   "source": [
    "## Conclusion Basic Access\n",
    "There I am going to evaluate the basic access for linking entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f3ec6a-8720-43f0-9c2d-e6472261afdb",
   "metadata": {},
   "source": [
    "### Results for Linking\n",
    "Now we look how we have been successful with linking to database with respect to different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3dd34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>mash_search</th>\n",
       "      <th>medvik_search_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>symptom</td>\n",
       "      <td>jemný fibrózní proužek</td>\n",
       "      <td>[(C0030848, Peyronie Disease), (C0227365, Taen...</td>\n",
       "      <td>[(D000077275, fibrózní dysplazie kraniofaciáln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>procedura</td>\n",
       "      <td>neoadjuvantní CHT</td>\n",
       "      <td>[(C0600558, Neoadjuvant Therapy), (C1422359, S...</td>\n",
       "      <td>[(D000014, abnormality vyvolané léky), (D00313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medikace</td>\n",
       "      <td>novalgin</td>\n",
       "      <td>[(C0917937, Novalgin)]</td>\n",
       "      <td>[(D004177, metamizol)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                    text  \\\n",
       "0    symptom  jemný fibrózní proužek   \n",
       "1  procedura       neoadjuvantní CHT   \n",
       "2   medikace                novalgin   \n",
       "\n",
       "                                         mash_search  \\\n",
       "0  [(C0030848, Peyronie Disease), (C0227365, Taen...   \n",
       "1  [(C0600558, Neoadjuvant Therapy), (C1422359, S...   \n",
       "2                             [(C0917937, Novalgin)]   \n",
       "\n",
       "                              medvik_search_combined  \n",
       "0  [(D000077275, fibrózní dysplazie kraniofaciáln...  \n",
       "1  [(D000014, abnormality vyvolané léky), (D00313...  \n",
       "2                             [(D004177, metamizol)]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = inserted_space_data.copy()\n",
    "results[\"mash_search\"] = inserted_space_mash_linked_data[\"search\"]\n",
    "results[\"medvik_search_combined\"] = medvik_combined_search_data[\"search\"]\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6946b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osobní anamnéza:\n",
      "Number of empty: 11 (5.14018691588785 %)\n",
      "Mean from number of matches: 22.939252336448597\n",
      "Median from number of matches: 24.0\n",
      "Maximal of matches: 86\n",
      "Number of empty: 18 (8.411214953271028 %)\n",
      "Mean from number of matches: 459.1588785046729\n",
      "Median from number of matches: 11.5\n",
      "Maximal of matches: 13185\n",
      "\n",
      "NE osobní anamnéza:\n",
      "Number of empty: 4 (6.557377049180328 %)\n",
      "Mean from number of matches: 20.83606557377049\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 75\n",
      "Number of empty: 14 (22.950819672131146 %)\n",
      "Mean from number of matches: 190.34426229508196\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 5777\n",
      "\n",
      "medikace:\n",
      "Number of empty: 73 (23.934426229508198 %)\n",
      "Mean from number of matches: 14.462295081967213\n",
      "Median from number of matches: 8.0\n",
      "Maximal of matches: 82\n",
      "Number of empty: 101 (33.114754098360656 %)\n",
      "Mean from number of matches: 96.88196721311475\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 5134\n",
      "\n",
      "NE medikace:\n",
      "Number of empty: 1 (6.25 %)\n",
      "Mean from number of matches: 19.3125\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 50\n",
      "Number of empty: 4 (25.0 %)\n",
      "Mean from number of matches: 38.1875\n",
      "Median from number of matches: 1.0\n",
      "Maximal of matches: 233\n",
      "\n",
      "symptom:\n",
      "Number of empty: 36 (6.132879045996593 %)\n",
      "Mean from number of matches: 22.938671209540033\n",
      "Median from number of matches: 21.0\n",
      "Maximal of matches: 125\n",
      "Number of empty: 25 (4.258943781942079 %)\n",
      "Mean from number of matches: 303.05451448040884\n",
      "Median from number of matches: 10.0\n",
      "Maximal of matches: 27444\n",
      "\n",
      "NE symptom:\n",
      "Number of empty: 92 (8.984375 %)\n",
      "Mean from number of matches: 23.126953125\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "Number of empty: 62 (6.0546875 %)\n",
      "Mean from number of matches: 463.5546875\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 21785\n",
      "\n",
      "procedura:\n",
      "Number of empty: 39 (6.543624161073826 %)\n",
      "Mean from number of matches: 24.446308724832214\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 121\n",
      "Number of empty: 46 (7.718120805369128 %)\n",
      "Mean from number of matches: 936.8808724832214\n",
      "Median from number of matches: 15.5\n",
      "Maximal of matches: 28651\n",
      "\n",
      "\n",
      "all:\n",
      "Number of empty: 256 (9.133071708883339 %)\n",
      "Mean from number of matches: 22.33927934356047\n",
      "Median from number of matches: 25.0\n",
      "Maximal of matches: 138\n",
      "Number of empty: 270 (9.632536567962898 %)\n",
      "Mean from number of matches: 481.9782376025687\n",
      "Median from number of matches: 7.0\n",
      "Maximal of matches: 28651\n",
      "Number of empty in both search: 176\n"
     ]
    }
   ],
   "source": [
    "os_anamneza = results[results.label == \"osobní anamnéza\"]\n",
    "ne_os_anamneza = results[results.label == \"NE osobní anamnéza\"]\n",
    "medikace = results[results.label == \"medikace\"]\n",
    "ne_medikace = results[results.label == \"NE medikace\"]\n",
    "symptom = results[results.label == \"symptom\"]\n",
    "ne_symptom = results[results.label == \"NE symptom\"]\n",
    "procedura = results[results.label == \"procedura\"]\n",
    "    \n",
    "print(\"osobní anamnéza:\")    \n",
    "print_linking_stats(os_anamneza[\"mash_search\"])\n",
    "print_linking_stats(os_anamneza[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE osobní anamnéza:\")\n",
    "print_linking_stats(ne_os_anamneza[\"mash_search\"])\n",
    "print_linking_stats(ne_os_anamneza[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nmedikace:\")\n",
    "print_linking_stats(medikace[\"mash_search\"])\n",
    "print_linking_stats(medikace[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE medikace:\")\n",
    "print_linking_stats(ne_medikace[\"mash_search\"])\n",
    "print_linking_stats(ne_medikace[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nsymptom:\")\n",
    "print_linking_stats(symptom[\"mash_search\"])\n",
    "print_linking_stats(symptom[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nNE symptom:\")\n",
    "print_linking_stats(ne_symptom[\"mash_search\"])\n",
    "print_linking_stats(ne_symptom[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\nprocedura:\")\n",
    "print_linking_stats(procedura[\"mash_search\"])\n",
    "print_linking_stats(procedura[\"medvik_search_combined\"])\n",
    "\n",
    "print(\"\\n\\nall:\")\n",
    "print_linking_stats(results[\"mash_search\"])\n",
    "print_linking_stats(results[\"medvik_search_combined\"])\n",
    "print(\"Number of empty in both search:\", len(results[(results[\"mash_search\"].apply(lambda x: len(x) == 0)) & (results[\"medvik_search_combined\"].apply(lambda x: len(x) == 0))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec406b8-d613-4010-89fe-923fdb263f38",
   "metadata": {},
   "source": [
    "We can see, that most labels work quite similar to each others. One big exception is label \"medikace\" (in english medication). This label have significantly higher empty rate, but have less of matches. \n",
    "\n",
    "I this is caused by shorter text (have less of words), but these words are usually more concrete (as names of medicine)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a48c2",
   "metadata": {},
   "source": [
    "### Results for Mash and Medvik search\n",
    "Now I am going to evaluate results from GPT for linking.\n",
    "\n",
    "For this I have created a sample of 100 entries, which I have send to GPT to find best match. From them I picked up another sample of 35 entries which I have evaluated manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10a07e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 100\n",
      "Number of empty Linking for medvik_search_combined: 11\n",
      "Number of empty Linking for Mash_search: 10\n",
      "Number of not assigned for Medvik: 39\n",
      "Number of not assigned for Mash: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples: {}\".format(len(explanation)))\n",
    "\n",
    "print(\"Number of empty Linking for medvik_search_combined: {}\".format(explanation[\"medvik_search_combined\"].apply(lambda x: len(x) == 0).sum()))\n",
    "print(\"Number of empty Linking for Mash_search: {}\".format(explanation[\"mash_search\"].apply(lambda x: len(x) == 0).sum()))\n",
    "\n",
    "print(\"Number of not assigned for Medvik: {}\".format(explanation[\"medvik_explanation\"].apply(lambda x: x is None).sum()))\n",
    "print(\"Number of not assigned for Mash: {}\".format(explanation[\"mash_explanation\"].apply(lambda x: x is None).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f61b6e-b54e-49fe-a36c-360dfe2f680c",
   "metadata": {},
   "source": [
    "We can see, that there is high number of not assigned in both searches. But in Medvik it is much higher. The higher number in Medvik is because we have to drop very long searches. In the future accesses it is important to handle the long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7629bfed-9848-4de1-b252-0add47bb4173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "asign = []\n",
    "for j in explanation.sample(35, random_state=42).index:   \n",
    "    if explanation[\"medvik_explanation\"][j] is not None:\n",
    "        x = explanation[\"medvik_explanation\"][j]\n",
    "        asign.append((explanation[\"text\"][j], \"Medvik\", \"{} ({})\".format(x[1], x[2])))\n",
    "    if explanation[\"mash_explanation\"][j] is not None:\n",
    "        x = explanation[\"mash_explanation\"][j]\n",
    "        asign.append((explanation[\"text\"][j], \"Mash\", \"{} ({})\".format(x[1], x[2])))\n",
    "    if explanation[\"mash_explanation\"][j] is None and explanation[\"medvik_explanation\"][j] is None:\n",
    "        asign.append((explanation[\"text\"][j], \"None\", \"Empty\"))\n",
    "\n",
    "i = 0\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Partially\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Wrong\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "i += 1\n",
    "assigment = \"Right\"\n",
    "asign[i] = (asign[i][0], asign[i][1], asign[i][2], assigment)\n",
    "\n",
    "assert len(set([i[3] for i in asign])) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da440789-4211-414e-b8a9-e1155196eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not assigned medvik: 15\n",
      "Mistakes from medvik: 13\n",
      "Partially right from medvik: 5\n",
      "Right from medvik: 2\n",
      "\n",
      "Not assigned mash: 11\n",
      "Mistakes from mash: 13\n",
      "Partially right from mash: 5\n",
      "Right from mash: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Not assigned medvik:\", 35 - len([i for i in asign if i[1] == \"Medvik\"]))\n",
    "print(\"Mistakes from medvik:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]))\n",
    "print(\"Partially right from medvik:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]))\n",
    "print(\"Right from medvik:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]))\n",
    "\n",
    "print(\"\\nNot assigned mash:\", 35 - len([i for i in asign if i[1] == \"Mash\"]))\n",
    "print(\"Mistakes from mash:\", len([i for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]))\n",
    "print(\"Partially right from mash:\", len([i for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]))\n",
    "print(\"Right from mash:\", len([i for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618bdf2-ca7a-41a5-a697-1623b7831f08",
   "metadata": {},
   "source": [
    "The results are not so good (but it was base line).\n",
    "\n",
    "For medvik we have got 20 % for at least partially right linking. And 6 % for completely right linking.\n",
    "\n",
    "For mash we have got 31 % for at least partially right linking. And 17 % for completely right linking.\n",
    "\n",
    "These results need improvement. For this reason I create new Improved linking based on different method. But before it I look at the wrong, partially and right results and observe if there is some pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f477d6ba-305e-4d4e-ac85-b0bbb6e8a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text wrong in medvik and mash: ['MG vlevo', 'bez šelestu', 'neostře konturované ložisko 7x5mm', 'bez poruchy kinetiky myokardu', 'norm. velikost srdeč. oddílů', 'jizevnaté změny v ZDK', 'tumorozní ložisko']\n",
      "text wrong only in medvik ['benigní verifikované ložisko v HKK', 'játra bez solidních patologických ložiskových změn', 'USG pravé mammy a axilly', 'mírný sekund lymfedém pod axilou, v zadní axil. řase', 'apokrinní metaplazií a místy i adenóza', 'mastitis: ne']\n",
      "text wrong only in mash ['někdy tahv oblasti jizvy', 'subjektivně bez bolestí', 'močový měchýř hypodenzní homogenní náplně', 'bránice hladká', 'fibropleurální změny', 'dlouhodobě stac. nález']\n",
      "\n",
      "text partially right in medvik and mash: ['parciální mastektomie vlevo']\n",
      "text partially right only in medvik ['močový měchýř hypodenzní homogenní náplně', 'bránice hladká', 'zn. krvácení', 'průjmy']\n",
      "text partially right only in mash ['játra bez solidních patologických ložiskových změn', 'USG pravé mammy a axilly', 'uzliny fyziologické', 'operace: 0']\n",
      "\n",
      "text right in medvik and mash: ['rekonstrukce prsu', 'kašel']\n",
      "text right only in medvik []\n",
      "text right only in mash ['nemohola jíst', 'zn. krvácení', 'mastitis: ne', 'inf. glucosi 10% 500 ml']\n"
     ]
    }
   ],
   "source": [
    "med = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Wrong' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext wrong in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text wrong only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text wrong only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Partially' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext partially right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text partially right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text partially right only in mash\", [i for i in mash if i not in med])\n",
    "\n",
    "med = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Medvik\"]\n",
    "mash = [i[0] for i in asign if i[3] == 'Right' and i[1] == \"Mash\"]\n",
    "print(\"\\ntext right in medvik and mash:\", [i for i in med if i in mash])\n",
    "print(\"text right only in medvik\", [i for i in med if i not in mash])\n",
    "print(\"text right only in mash\", [i for i in mash if i not in med])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da14b0-aa26-4cd8-b748-b1cfb5d0a426",
   "metadata": {},
   "source": [
    "- We can see, that there are higher percentage of partially right. This is because we have been looking for one sumarizing linking. But very often such linking doesn't exists. At these cases we only find linking which corresponds to part of the text not for the whole. \n",
    "- The completely right one, are usualy very short (I think the reason is same as above)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
